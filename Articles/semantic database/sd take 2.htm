<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>New Page 1</title>
</head>

<body>

<p align="center">Semantic Database</p>
<p align="center">Concept<br>
Architecture<br>
Implementation<br>
<br>
<i>“No word has a value that can be identified independently of what else is in 
its vicinity.”</i></p>
<h2>Introduction</h2>
<p>This article discusses the concept of a semantic database in several 
sections:</p>
<ul>
	<li>Discussion of the concept and need for a semantic database</li>
	<li>Architectural Implications</li>
	<li>Implementation on top of an RDBMS</li>
	<li>Unit tests to vet basic insert and query operations (we'll leave update 
	and delete for later)</li>
</ul>
<p>Part II will demonstrate the semantic database in action in the
<a href="http://www.higherorderprogramming.com/developers-1-1-2/">Higher Order 
Programming Environment</a> with a useful application.&nbsp; If you are 
unfamiliar with HOPE,
<a href="http://www.higherorderprogramming.com/developers-1-1-2/">this page</a> 
will refer you to the other articles here on Code Project.</p>
<p>As many of my readers will be used to by now, this is definitely going to be 
a walk on the wild side.&nbsp; The concepts, architecture, and implementation 
will hopefully challenge your preconceptions of what data is, and by corollary, 
what a semantic database is.</p>
<p>The reader will hopefully also forgive the rather deep foray into a 
non-technical discussion regarding semantics, as it is important to convey the 
necessary foundational information.</p>
<h3>Where's the Code?</h3>
<p>As usual, the code can be cloned or forked from
<a href="https://github.com/cliftonm/HOPE">GitHub</a>.&nbsp; In Part II, I'll 
have a branch specific to the code that goes along with that article.</p>
<h2>What is a Semantics?</h2>
<p>Semantics is an emerging field of research and development in information 
science, however, the concept has been around for a lot longer than computers!&nbsp;
To begin with, semantics is the branch of linguistics and logic concerned with 
meaning.&nbsp; This can be broken down into three major categories:</p>
<ul>
	<li>Formal Semantics<ul>
		<li>Logical aspects of meaning:<ul>
			<li>Sense</li>
			<li>Reference</li>
			<li>Implication</li>
			<li>Logical form</li>
		</ul>
		</li>
	</ul>
	</li>
	<li>Lexical Semantics<ul>
		<li>Word meaning</li>
		<li>Word relations</li>
	</ul>
	</li>
	<li>Conceptual Semantics<ul>
		<li>Cognitive structure of meaning</li>
	</ul>
	</li>
</ul>
<p>Or, to put it a bit more concretely:</p>
<ul>
	<li>Semantics is the study of meaning</li>
	<li>It focuses on the relationship between:<ul>
		<li>Signifiers: words, phrases, signs and symbols</li>
		<li>
		
		<p>Denotation: what they stand for</li>
	</ul>
	</li>
</ul>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="center"><i>“No word has a value that can be identified independently of what else 
is in its vicinity.”</i> <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
-- (de Saussure, Ferdinand, 1916, The Course of General Linguistics)</p>
<h3>What is the Typical Concept of a Semantic Database?</h3>
<p>First off, the term &quot;semantic database&quot; is classically used in conjunction 
with the phrase &quot;semantic data model<sup>1</sup>&quot;.&nbsp; And when you see the 
phrase &quot;semantic data&quot;, this usually implies some association with the Semantic 
Web<sup>2</sup>, the Web Ontology Language (OWL)<sup>3</sup>, and the Resource 
Description Format (RDF)<sup>4</sup>.</p>
<h4>The Semantic Web</h4>
<p><i>&quot;The semantic web is a vision of information that can be readily 
interpreted by machines, so machines can perform more of the tedious work 
involved in finding, combining, and acting upon information on the web.&nbsp; 
The Semantic Web, as originally envisioned, is a system that enables machines to 
&quot;understand&quot; and respond to complex human requests based on their meaning. Such 
an &quot;understanding&quot; requires that the relevant information sources be 
semantically structured.&quot;</i><sup>2</sup></p>
<h4>OWL and RDF</h4>
<p>Unfortunately, the original concept and phrase, coined by Tim Berners-Lee 
(also the inventor of the World Wide Web) has been somewhat hijacked by OWL and 
RDF.&nbsp; OWL and RDF primarily focus on what is known as &quot;triples&quot; -- 
subject-predicate-object expressions, where &quot;[t]he subject denotes the resource, 
and the predicate denotes traits or aspects of the resource and expresses a 
relationship between the subject and the object.&quot;<sup>4</sup>&nbsp; The roots of 
this can be traced to the 1960's, when &quot;Richard Montague proposed a system for 
defining semantic entries in the lexicon in terms of the lambda calculus. In 
these terms, the syntactic parse of the sentence John ate every bagel would 
consist of a subject (John) and a predicate (ate every bagel); Montague 
demonstrated that the meaning of the sentence altogether could be decomposed 
into the meanings of its parts and in relatively few rules of combination.&quot;<sup>8</sup> </p>
<p>However, this correlates very poorly with the pure concept of semantics, 
especially with regards to relationships and structure.&nbsp; While a 
subject-predicate-object expression defines the relationship between the subject 
and object, it in no way defines the relationship <i>between</i> subjects, and
<i>between</i> objects.&nbsp; Furthermore, an S-P-O also fails to express the <i>composition</i>, 
or <i>structure</i> of an object or subject, which, from a semantic perspective, 
is critical.</p>
<p>Obviously one can, with little thought, create a database of 
subject-predicate-object triples.&nbsp; One can then even query the database for 
kinds of relationships (via their predicates) that subject have to all objects 
in the domain (or objects and their subjects.)&nbsp; The problem is, this 
approach leaves one open to the challenges of the semantic web: &quot;vastness, 
vagueness, uncertainty, inconsistency, and deceit.&quot;<sup>2</sup> Why?&nbsp; 
Because triples do not actually convey much meaning in a machine usable sense 
and are therefore prone to the aforementioned issues.&nbsp; 
Ironically, while a triple includes the relationship between subject and object, 
it does not say anything about the structure of the subject or the object (or 
even the predicate, which could have its own structure as well.)&nbsp; Take, for 
example, the issue of underspecification:</p>
<p><i>&quot;...meanings are not complete without some elements of context. To take an 
example of one word, red, its meaning in a phrase such as red book is similar to 
many other usages, and can be viewed as compositional.[6] However, the colours 
implied in phrases such as red wine (very dark), and red hair (coppery), or red 
soil, or red skin are very different. Indeed, these colours by themselves would 
not be called red by native speakers. These instances are contrastive, so red 
wine is so called only in comparison with the other kind of wine (which also is 
not white for the same reasons).&quot;</i><sup>6</sup></p>
<p>If the full structure is persisted along with the data (&quot;red&quot;):</p>
<p><img border="0" src="colors.png" width="589" height="152"></p>
<p>and that structure is retrieved when querying for, say &quot;things that are red&quot;, 
then its meaning is not ambiguous.&nbsp; </p>
<p><img border="0" src="note.png" width="24" height="32"> We note that the parent 
elements are valueless -- they are only placeholders referencing the child 
element &quot;Color.&quot;</p>
<h3>What is the &quot;Correct&quot; Concept of a Semantic Database?</h3>
<p>Like Alice in Wonderland, we have to go down a few rabbit holes to figure 
this out.&nbsp; </p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="center"><i>&quot;Many sites are generated from structured data, which is often stored in 
databases. When this data is formatted into HTML, it becomes very difficult to 
recover the original structured data. Many applications, especially search 
engines, can benefit greatly from direct access to this structured data.&quot;</i><sup>5</sup></p>
<p>In other words, by exposing the semantics of the data, machines can then 
utilize the information in more interesting ways than just storing it or 
displaying it.&nbsp; A classic example is a website that contains a phone 
number.&nbsp; If the phone number is has a semantic tag, then your smart phone 
can easily offer it up as number to dial.&nbsp; Contrast this with the hoops an 
application has to go through to scan a page and find text that matches any 
number of styles of presenting a phone number, validating that it is actually a 
number rather than a math expression that looks like &quot;619-555-1212&quot;, etc.</p>
<h4>Structured Data</h4>
<p>In the above quote, you'll notice the phrase &quot;<i>recover the original 
structured data.</i>&quot;&nbsp; This implies that the data has structure -- it's not 
just a field, but the fields mean something and can have sub-structures -- in 
other words, the structured data is a tree.</p>
<p>Here's a couple examples:</p>
<p align="center"><img border="0" src="latlon.png" width="188" height="244">&nbsp;&nbsp;&nbsp;&nbsp;
<img border="0" src="sphone.png" width="432" height="169" style="margin-bottom:40px"></p>
<p>Next, we need to understand the concept of &quot;ontology&quot;, a term that is often 
involved in discussions regarding semantics.</p>
<h4>Ontology</h4>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="center"><i>&quot;An ontology is an explicit specification of a conceptualization.&quot;<br>
</i>&nbsp; -- Gruber, Tom (1993); &quot;A Translation Approach to Portable Ontology 
Specifications&quot;, in Knowledge Acquisition, 5: 199-199</p>
<p>Earlier I pointed out that the S-P-O triple does not define the relationship <i>
between</i> subjects, and
<i>between</i> objects.&nbsp; This is where ontology comes in.&nbsp; While in 
the abstract, &quot;ontology&quot; means &quot;the branch of metaphysics dealing with the 
nature of being,&quot; in information science,<i> &quot;an ontology is defined as a formal, explicit specification of a shared 
conceptualization. It provides a common vocabulary to denote the types, 
properties and interrelationships of concepts in a domain.&quot;</i><sup>9</sup><i> </i>And notice:<i> &quot;Ontologies are the structural frameworks for organizing information and 
are used in ...the <u>Semantic Web</u>...&quot;&nbsp; </i></p>
<p>Semantics are useful for understanding the structure of a &quot;thing&quot;, however we 
need ontologies to relate things with other things.&nbsp; Therefore, one would expect that 
a semantic database be relational -- it should be able to relate structured data 
into ontologies.</p>
<p>Here is an example instance of the Friend of a Friend<sup>10</sup> ontology (from the
W3C SKOS Core Guide<sup>11</sup>):</p>
<p align="center"><img border="0" src="foaf.png" width="613" height="506"></p>
<p>The SKOS Core Vocabulary defines two properties of a semantic relationship:</p>
<ol>
	<li>The relationship between the two structures defines one as being 
	&quot;broader&quot; or &quot;narrower&quot; with relation to the other</li>
	<li>An associative relationship, in which the two structures are &quot;related&quot; 
</li>
</ol>
<p>In the world of the semantic web, and RDF Schema (RDFS)<sup>12</sup> is used 
to describe ontologies &quot;...otherwise called RDF vocabularies, intended to 
structure RDF resources. These resources can be saved in a triplestore to reach 
them with the query language SPARQL.&quot;<sup>12</sup>&nbsp; For example: &quot;A typical 
example of an rdfs:Class is foaf:Person in the Friend of a Friend (FOAF) 
vocabulary. An instance of foaf:Person is a resource that is linked to the class 
foaf:Person using the rdf:type property, such as in the following formal 
expression of the natural language sentence : 'John is a Person'.&quot;<sup>12</sup></p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>We see two concepts emerging:</p>
<ol>
	<li>The relationship between data structures is itself a hierarchical 
	structure</li>
<li>A semantic structure can be associated with another structure to create 
ontologies</li>
</ol>
<p>This guides us in understanding what a semantic database should provide.</p>
<h2>A Semantic Database </h2>
<p>In a semantic database (going back to the very early definition of 
semantics), the schema:</p>
<ol>
	<li>describes denotations</li>
	<li>describes relationships between denotations</li>
</ol>
<p>The job of the database then is to associate signifiers (values) to those 
denotations.&nbsp; Therefore:</p>
<ol>
	<li>Structure resolves to concrete properties to which instance values can 
	be associated</li>
</ol>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>Importantly though, <i>the structure is instantiated with each instance.</i>&nbsp; 
This allows the structure to be retrieved along with the value(s).&nbsp; We will 
see what this means (and why what I'm implementing is going to seem so 
controversial) later.</p>
<h3>Why not use a Relational Database?</h3>
<p>In the implementation section of this article, I'll be working a lot with RSS 
feeds, so let's take a look at a typical implementation in an RDBMS for 
persisting an RSS Feed and its entries.&nbsp; First off, the schema probably 
looks something like this:</p>
<table border="0" width="100%">
	<tr>
		<td>
		<ul>
			<li>RSS_Feed_Name<ul>
				<li>Name : text</li>
			</ul>
			</li>
			<li>RSS_Feed_Item<ul>
				<li>FK_RSS_Feed_Name</li>
				<li>Title : text</li>
				<li>Description: text</li>
				<li>PubDate : date</li>
				<li>Url : text</li>
			</ul>
			</li>
			<li>RSS_UI<ul>
				<li>FK_RSS_Feed_Item</li>
				<li>Visited : bool</li>
				<li>Displayed : bool</li>
			</ul>
			</li>
		</ul>
		</td>
		<td>
		<p align="center">
		<img border="0" src="rdbms1.png" width="324" height="132"></td>
	</tr>
</table>
<p>(Here the RSS_UI is intended to persist whether a feed item has been 
displayed previously in a list or whether it is a new feed, and whether the user 
actually visited the URL associated with the feed item.)</p>
<p>Notice how the field names are high level abstractions.&nbsp; Given the field 
name, one has no idea whether the &quot;Title&quot; refers to an RSS feed, a book, or a 
the title given to a person.&nbsp; Adding &quot;RSS_Feed_&quot; to the field names is 
cumbersome and non-traditional.&nbsp; Furthermore, when we perform the query 
&quot;select * from RSS_Feed_Item&quot;, we get a collection of rows in the order that the 
fields were described in the schema.&nbsp; However, these are just values -- we 
all too often forget that the data returned has actually no semantic meaning, it 
is the UI that labels the columns for us so we know what the data is.&nbsp; </p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>Even more importantly, in an RDBMS, relationships are driven by:</p>
<ul>
	<li>Cardinality</li>
	<li>Normalization rules</li>
	<li>&quot;Logical&quot; groupings of fields</li>
</ul>
<p>This process can be so automatic when we create a schema that we are hardly 
consciously aware that we are doing it.&nbsp; The result are associations that 
are not semantic but rather abstracted, un-natural structural relationships, 
(ideally) restricted to established foreign key declarations.</p>
<p>However, as we will see, we can implement a semantic database on top of an 
RDBMS.</p>
<h3>Why not use a NoSQL Database?</h3>
<p>NoSQL databases are document-oriented and they do not support relationships 
between documents such that one can construct a query that consists of joins 
that is handled by the database engine.&nbsp; Instead, in a NoSQL database, 
joins are resolved by the client, which requires potentially numerous round 
trips to the database to acquire all the information and then build it into a 
coherent structure.&nbsp; This makes NoSQL database completely unsuitable for 
the task at hand.</p>
<h3>Why not use a Graph Database?</h3>
<p>Graph databases do seem to be a possibility and will be investigated further.&nbsp; 
If we read about Neo4j:</p>
<p>From Neo4j's website:</p>
<p><i>&quot;...a graph is just a collection of vertices and edges—or, in less 
intimidating language,a set of nodes and the relationships that connect them. 
Graphs represent entities as nodes and the ways in which those entities relate 
to the world as relationships.&quot; -</i> Robinson, Ian, &amp; Webber, Jim, &amp; Eifrem, 
Emil (2013). <i>Graph Databases.</i> O'Reilly, pg 1 (free download
<a href="http://www.graphdatabases.com/">here</a>.)</p>
<p>Importantly, with regards to traditional relational databases:</p>
<p><i>&quot;...relational databases were initially designed to codify paper forms and 
tabular structures—something they do exceedingly well—they struggle when 
attempting to model the ad hoc, exceptional relationships that crop up in the 
real world. Ironically, relational databases deal poorly with relationships.&nbsp; 
Relationships do exist in the vernacular of relational databases, but only as a 
means of joining tables. In our discussion of connected data in the previous 
chapter, we mentioned we often need to disambiguate the semantics of the 
relationships that connect entities, as well as qualify their weight or 
strength. Relational relations do nothing of the sort.&quot; </i>- (ibid, pg 11)</p>
<p>And:</p>
<p><i>&quot;Relationships are first-class citizens of the graph data model, unlike 
other database management systems, which require us to infer connections between 
entities using contrived properties such as foreign keys, or out-of-band 
processing like map-reduce. By assembling the simple abstractions of nodes and 
relationships into connected structures, graph databases enable us to build 
arbitrarily sophisticated models that map closely to our problem domain. The 
resulting models are simpler and at the same time more expressive than those 
produced using traditional relational databases and the other NOSQL stores.&quot;</i> 
- (ibid, pg 6)</p>
<p>However, it would appear that a typical graph database focuses on the ontology of information 
-- it has no 
concept of the actual structures that define the properties of a node.&nbsp; 
This is a result of the concept of &quot;facts&quot;:&nbsp; <i>&quot;When two or more domain 
entities interact for a period of time, a fact emerges. We represent these facts 
as separate nodes, with connections to each of the entities engaged in that 
fact.&quot;</i> - (ibid, pg 66)</p>
<p>We can see this in the examples given for creating a graph database.&nbsp; 
From pg 41:</p>
<p align="center"><img border="0" src="graphdb1.png" width="337" height="137"></p>
<p>We have &quot;fact&quot; nodes:</p>
<ul>
	<li>William Shakespeare</li>
<li>The Tempest</li>
	<li>Juilias Ceasar</li>
</ul>
<p>This information lacks semantic context, for example indicating that 
&quot;William Shakespeare&quot; is a playwright or that &quot;The Tempest&quot; is a play.&nbsp; 
Interestingly, this semantic information becomes an arbitrary label in the
Cypher<sup>14</sup> query 
fragment <code>bard=node:author(lastname='Shakespeare')</code>.&nbsp; From the 
query we can determine that William Shakespeare is a bard, however, this 
information is completely lost in the graph database!&nbsp; </p>
<p>To put it another way, if we follow the &quot;fact&quot; best practice, it becomes 
impossible to query a graph database for data by specifying a semantic context.&nbsp; 
I cannot ask the graph database &quot;show me all the people that are bards&quot; unless I 
explicitly create a node called &quot;bard&quot; with a relationship to William 
Shakespeare.&nbsp; This problem stems partially from the fact that a graph 
database represents a specific domain: <i>&quot;By assembling the simple abstractions 
of nodes and relationships into connected structures, graph databases enable us 
to build arbitrarily sophisticated models that map closely to our problem 
domain.&quot;</i> - (ibid, pg 6).&nbsp; At best, we can say a node with properties &quot;firstname&quot; 
and &quot;lastname&quot; represents a &quot;person&quot;, but we can say nothing else about that 
person, such as distinguishing the person from the playwright, the producer, or 
the actor, <i>except</i> through a relationship with another concrete node, 
where the relationship provides further semantic meaning, such as &quot;wrote_play&quot;, 
or &quot;produced_play&quot; or &quot;acted_in&quot;.&nbsp; </p>
<p>Therefore, with regards to semantic structure, a graph database, while an 
excellent tool for creating ontologies of concrete entities, is not appropriate 
for abstract structural elements that have semantic significance but no values 
(which would have to be represented as nodes without properties), nor does a 
graph database properly semanticize property values, except as &quot;field names&quot; 
which, like traditional databases, the semantics are not accessible as part of 
the data.</p>
<p>Nonetheless, there is much guidance in the literature on graph databases that 
is valuable when designing a semantic database, and that is:</p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="center"><i>There is relevant meaning in the connections between semantic structures 
comprising the ontology.</i> </p>
<h2>A Semantic Database Architecture</h2>
<p>In the above discussion, we come to several important observations:</p>
<ol>
	<li>An ontology emphases the relationship of entities rather than defining 
	the entity structure.</li>
	<li>Semantics emphasizes the structure but not the relationships between 
	structures (the ontology.)</li>
</ol>
<p>Furthermore, with regards to current database options:</p>
<ol>
	<li>Graph databases typically capture ontologies of facts rather than 
	semantics and their structures</li>
	<li>Relational databases capture &quot;logical&quot; relationships rather than 
	&quot;natural&quot; semantic structures and ontologies</li>
	<li>NoSQL databases require that the client provides the implementation for 
	supporting relationships, the only support NoSQL provides is a very limited 
	&quot;document ID&quot; scaffolding.</li>
</ol>
<p>What is needed is with regards to a semantic database is:</p>
<ol>
	<li>The ability to create ontologies from semantics</li>
	<li>The ability to define the natural structure of the semantic elements</li>
</ol>
<p>Using our RSS_Feed_Item example, we can put together a mockup of what the 
natural structure of the concept &quot;RSS_Feed_Item&quot; looks like:</p>
<ul>
	<li>RSS_Feed_Item<ul>
		<li>RSS_Feed_Name<ul>
			<li>Name<ul>
				<li>Text<ul>
					<li>Value : text</li>
				</ul>
			</li>
			</ul>
		</li>
		</ul>
	</li>
	<li>RSS_Feed_Title<ul>
		<li>Title<ul>
				<li>Text<ul>
					<li>Value : text</li>
				</ul>
			</li>
			</ul>
		</li>
		</ul>
	</li>
	<li>RSS_Feed_Description<ul>
		<li>Description<ul>
				<li>Text<ul>
					<li>Value : text</li>
				</ul>
			</li>
			</ul>
		</li>
		</ul>
	</li>
	<li>RSS_Feed_PubDate<ul>
		<li>Publication_Date<ul>
			<li>Date<ul>
					<li>Value : date</li>
				</ul>
			</li>
			</ul>
		</li>
		</ul>
	</li>
	<li>RSS_Feed_Url<ul>
		<li>URL<ul>
				<li>Text (see comment below)<ul>
					<li>Value : text</li>
				</ul>
			</li>
			</ul>
		</li>
		</ul>
	</li>
	</ul>
</li>
</ul>
<p>(It certainly can also be argued that &quot;URL&quot; should be broken down into scheme 
name, domain name and resource path, but we'll keep it simple for now.)</p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="left">The first thing to note with this structure is that queries can 
queries can be made at any level in the structure with varying degrees of 
meaning loss.&nbsp; For example, the query “select URL from RSS_Feed_Url” has 
some contextual loss, as we still know that the values are associated with a URL 
structure, but URL is no longer identified as being an RSS Feed URL.&nbsp; A 
query like “select Value from URL” has complete contextual loss -- all we get 
back are a collection of strings.&nbsp; Incidentally, this is the equivalent of 
querying an RDBMS “select URL from RSS_Feed_Item”.&nbsp; In the semantic 
database implementation that I propose here, the query &quot;select Value from URL&quot; 
would actually not be possible because Value is a native type, not a semantic 
type.</p>
<h3 align="left">Using an RDMS to host a Semantic Database</h3>
<p align="left">However, a semantic database can be built on top of an RDBMS.&nbsp; 
We can leverage useful features of an RDBMS:</p>
<ul>
	<li>
	<p align="left">foreign key constraints</p></li>
	<li>
	<p align="left">server-side joins</p></li>
	<li>
	<p align="left">unique key constraints</p></li>
	<li>
	<p align="left">unique key indexing</p></li>
</ul>
<p align="left">When hosted by an RDBMS, we see the following artifacts:</p>
<ul>
	<li>
	<p align="left">Tables represent structure</p></li>
	<li>
	<p align="left">Foreign keys describe sub-structures</p></li>
	<li>
	<p align="left">Joins are used to join together structures</p></li>
	<li>
	<p align="left">In a left join, all-null native types for a semantic type takes on 
	the specific meaning that there 
	is no structure instance</p></li>
	<li>
	<p align="left">The primary key is almost exclusively relegated to the role 
	of resolving joins through the foreign key</p></li>
	<li>
	<p align="left">There is significant more emphasis on the unique key (single 
	field or composite) for performing insert, update, and delete transactions 
	on native types.</p></li>
</ul>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>Contrary to an RDBMS, where relationships are driven by cardinality, 
normalization, and logical structuring of fields, in a semantic database, 
relationships are driven by the semantic structure itself.&nbsp; This, by its 
very nature, allows a semantic database to be more adaptive to new structures 
that encapsulate new meaning.</p>
<h3>Unfolding a Semantic Database Structure</h3>
<p>Using the RSS feed example, an unfolded structure of tables in a database 
would look something like this:</p>
<p><img border="0" src="struct1.png" width="798" height="324"><br>
<br>
Notice that there are only two tables with actual values (Text and URL).&nbsp; 
Everything else is &quot;substrate&quot; - it's there only for its structural relevance 
and consists only of foreign keys pointing the next layer of generalized 
concept.&nbsp; While most structures have 1:1 relationships with their 
generalization, we see that RSS_Feed_Item is a composite of four distinct 
structures (this is its specific ontology.)&nbsp; </p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>In object oriented terms, we can clearly see the &quot;is a kind of&quot; and &quot;has a&quot; 
relationships, however, it should be noted that a semantic database is in no way 
an implementation of an OODBMS, again for the same reason -- objects tend to be 
logical constructs for the convenience of the programmer rather than natural 
semantic constructs.&nbsp; However, a semantic structure quite naturally fits 
into the OO paradigm.</p>
<h3>Folding a Semantic Database Structure</h3>
<p>The typical structure however is illustrated more cleanly as a tree:</p>
<p><img border="0" src="struct2.png" width="687" height="354"></p>
<h3>Implementation in an RDBMS</h3>
<p>This is what the schema looks like in an RDBMS (and this is where I really 
start getting the &quot;you're crazy&quot; looks):</p>
<p><img border="0" src="sdmodel-subset.png" width="744" height="526"><br>
<img border="0" src="note.png" width="24" height="32">&nbsp;
Two things stand out:</p>
<table border="0" width="100%">
	<tr>
		<td width="302">
		<img border="0" src="rssfeeditem.png" width="199" height="142"></td>
		<td>The “deepest” semantic types are almost always composed just of 
		foreign keys.</td>
	</tr>
	<tr>
		<td width="302"><img border="0" src="nt1.png" width="251" height="57"></td>
		<td>Tables with native types are very “thin”, having very few fields.</td>
	</tr>
</table>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p align="left">What's interesting about this implementation is that we can now 
ask some potentially useful questions:</p>
<ul>
	<li>
	<p align="left">What are all the URL’s in the database?</p></li>
	<li>
	<p align="left">What are the URL’s we have visited?</p></li>
	<li>
	<p align="left">What URL’s are associated with feeds?</p></li>
	<li>
	<p align="left">What are all the values of “Title”?</p></li>
	<li>
	<p align="left">What are all the feed names?</p></li>
</ul>
<p>These are not questions that we can necessarily ask of an RDBMS, especially 
when a more general concept like &quot;URL&quot; is embedded as a field across multiple 
tables: RSS Feed URL's, browser bookmark URL's, document embedded URL's, etc.&nbsp; 
Even a well-architected database will have its limitations.</p>
<p>Furthermore, because of how the more general semantic types are joined to 
contextual types, we can ask:</p>
<ul>
	<li>Which feed items have I visited?</li>
	<li>Which feed items are bookmarked (I did not show the bookmark semantic 
	types in the diagram)</li>
</ul>
<p>Even more importantly (as an example), when we visit a page in a browser, we 
can use the same more generalized URL type with a specialized &quot;browser visited&quot; 
type, allowing us to ask specifically:</p>
<ul>
	<li>What are all the feed items I've visited?</li>
	<li>What are all the web pages I've visited directly in my browser?</li>
	<li>What are all the URL's in total that I've visited?</li>
</ul>
<p>Hopeful this demonstrates how a semantic database can adapt to new structures 
that then creates new contexts that can then be queried in new ways.&nbsp; </p>
<h3>Some Benefits of a Semantic Database</h3>
<ul>
	<li>By preserving semantic structure, we can query the database at different 
	levels of semantic meaning, from very specific to very general.<ul>
		<li>For example, the semantic type “Title” is very general but allows us 
		to ask “what are all the values of things having the meaning “Title”?</li>
	</ul>
</li>
<li>By inspecting the relationships, we can ask “what are the things having 
“Title” in their meaning?</li>
	<li>When we query the database, we don’t just get back a list of records – 
	we get back fully “rehydrated” semantic types.</li>
<li>In actual implementation, the need for an ORM layer is eliminated:<ul>
		<li>We pass in semantic structures as actual C# objects</li>
		<li>We get back semantic structures as actual C# objects</li>
	</ul>
</li>
</ul>
<h3>Some Drawbacks of a Semantic Database</h3>
<ul>
	<li>Tables and their fields are organized by hierarchical rather than 
	logical structure:<ul>
		<li>We usually think about organizing information into logical 
		associations and relationships</li>
		<li>Hierarchical organization creates many more tables<ul>
			<li>The number of joins in a query can degrade performance.</li>
			<li>Multiple insert operations are required to create the semantic 
			type’s hierarchy. </li>
		</ul>
		</li>
		<li>Designing hierarchies isn’t easy<ul>
			<li>We need to learn how to think about multiple levels of 
			abstraction.</li>
			<li>We need to think carefully about unique native types and unique 
			semantic types.</li>
		</ul>
		</li>
		<li>Writing SQL queries by hand is painful:<ul>
			<li>lots of joins, often with multiple references to the native type 
			tables making it hard to keep track of which FK join is associated 
			with what meaning-value.</li>
		</ul>
	</li>
	<li>Writing insert statements by hand is even more painful:<ul>
			<li>multiple inserts from the bottom up, requiring the ID of the 
			child table to populate the foreign key in the parent table.</li>
		</ul>
	</li>
	</ul>
</li>
</ul>
<h3>Addressing Some of the Drawbacks</h3>
<p>A Semantic Database engine can address some of these drawbacks:</p>
<ul>
	<li>Automating SQL query generation<ul>
		<li>Hides the hierarchy and table joins</li>
	</ul>
</li>
<li>Automating SQL inserts<ul>
		<li>Managing all the necessary FK ID’s</li>
	</ul>
</li>
<li>Improving Performance<ul>
		<li>Caching queries so the engine doesn’t have to re-create the SQL 
		statement every time.</li>
		<li>Use prepared statements so the server isn’t parsing and analyzing 
		the query statement every time it’s used.</li>
	</ul>
</li>
</ul>
<h2>Prototyping and Implementation</h2>
<p>A semantic database naturally deals with semantic structures.&nbsp; As I've 
already implemented a great deal of the infrastructure in the Higher Order 
Programming Environment (HOPE) project (the up to date list of articles can be 
found by visiting
<a href="http://www.higherorderprogramming.com/developers-1-1-2/">here</a>), I 
will be taking advantage of that code base.</p>
<p align="center"><img border="0" src="key-small.jpg" width="94" height="33"></p>
<p>It is highly recommended that the introductory articles are reviewed to help 
understand the following code.&nbsp; In the real demonstration that follows this 
section, I'll be taking advantage of the semantic editor and various &quot;receptor&quot; 
components, the semantic database being implemented as one such receptor.</p>
<h3>Unit Tests</h3>
<p>Unit tests are vital for verifying the expected behaviors when the user is 
expecting to trust our ability to properly persist and retrieve data (which is 
one of the reasons I'm also building this on top of an RDBMS rather than writing 
a completely new semantic database implementation.)&nbsp; Unit tests are also a 
good way of introducing the concepts and implementation of the semantic 
database.&nbsp; </p>
<p>You will notice the unit test structure as, basically:</p>
<ul>
	<li>Clean up the database for every test - this involves dropping tables</li>
	<li>Create the semantic structures and their configurations that will test 
	the desired behaviors</li>
	<li>Register these structures with the semantic database - this creates the 
	backing tables</li>
	<li>Perform the desired transactions</li>
	<li>Verify the results.</li>
</ul>
<p>An important consideration when working with any RDBMS, and this is true with 
regards to the semantic database as well, is the concept of unique keys, either 
single or composite fields.&nbsp; However, the semantic database also implements 
the concept of unique key &quot;types&quot;, where the type is the semantic element.&nbsp; 
This creates some interesting behaviors for which need to test, and the tests 
will help to document how to use the unique key field / type configurations.</p>
<h4>Database Configuration</h4>
<p>If you run the tests with a SQLite database, there is no configuration 
required -- the database file is created automatically and there are no 
permission issues.&nbsp; The semantic database also supports Postgres, which 
requires that:</p>
<ol>
	<li>a &quot;postgres.config&quot; file be placed in the &quot;HOPE\UnitTests\SemanticDatabaseTests\bin\Debug&quot; 
	folder.&nbsp; This file should consist of two lines:<ol>
		<li>The username</li>
		<li>The password</li>
	</ol>
</li>
<li>You will also need to manually create an empty database (no tables) called &quot;test_semantic_database&quot;</li>
</ol>
	<h4>Creating Tables From Semantic Structures</h4>
<p>This code:</p>
<pre>InitializeSDRTests(() =&gt; InitLatLonNonUnique());
sdr.Protocols = &quot;LatLon&quot;;
sdr.ProtocolsUpdated();
</pre>
<p>initializes the semantic database receptor and defines a semantic structure 
for &quot;LatLon&quot;.&nbsp; When <code>ProtocolsUpdated</code> is called, the semantic database 
creates the table &quot;LatLon&quot; with two fields, &quot;latitude&quot; and &quot;longitude&quot;.&nbsp; 
Tables are automatically created when a new semantic type is encountered.&nbsp; 
In this particular case, the semantic structure is instantiated thus:</p>
<pre>protected void InitLatLonNonUnique()
{
  SemanticTypeStruct sts = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs);
  Helpers.CreateNativeType(sts, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(sts, &quot;longitude&quot;, &quot;double&quot;, false);
}</pre>
<p>For our purposes, we won't worry about what decls or structs are, you can 
inspect the code in detail if you want to find out.&nbsp; The salient point is 
that a structure &quot;LatLon&quot; is created with two native types, both doubles, called 
&quot;latitude&quot; and &quot;longitude.&quot;&nbsp; Neither the structure nor the native types are 
defined as unique.&nbsp; </p>
<p><img border="0" src="note.png" width="24" height="32">&nbsp; While it seems odd, the reason strings are used for type names 
-- rather than, 
say, <code>typeof(double)</code> -- is because we're actually simulating what 
would normally be done in the semantic editor, which, being a user interface 
component, works mostly with strings for the names of things.</p>
<p><img border="0" src="database.png" width="32" height="32">The database 
implementation for creating the tables from a semantic structure is:</p>
<pre>/// &lt;summary&gt;
/// Create the table for the specified semantic structure, adding any SQL statements for making foreign key associations.
/// &lt;/summary&gt;
protected void CreateTable(string st, List&lt;string&gt; fkSql)
{
  // Fields and their types:
  List&lt;Tuple&lt;string, Type&gt;&gt; fieldTypes = new List&lt;Tuple&lt;string, Type&gt;&gt;();

  // Get the structure object backing the structure name.
  ISemanticTypeStruct sts = rsys.SemanticTypeSystem.GetSemanticTypeStruct(st);

  CreateFkSql(sts, fieldTypes, fkSql);
  CreateNativeTypes(sts, fieldTypes);
  dbio.CreateTable(this, st, fieldTypes);
}

/// &lt;summary&gt;
/// Any reference to a child semantic element is implemented as a foreign key.
/// Returns any foreign key creation sql statements in fkSql.
/// &lt;/summary&gt;
protected void CreateFkSql(ISemanticTypeStruct sts, List&lt;Tuple&lt;string, Type&gt;&gt; fieldTypes, List&lt;string&gt; fkSql)
{
  // Create FK's for child SE's.
  sts.SemanticElements.ForEach(child =&gt;
  {
    string fkFieldName = &quot;FK_&quot; + child.Name + &quot;ID&quot;;
    fieldTypes.Add(new Tuple&lt;string, Type&gt;(fkFieldName, typeof(long)));
    fkSql.Add(dbio.GetForeignKeySql(sts.DeclTypeName, fkFieldName, child.Name, &quot;ID&quot;));
  });
}

/// &lt;summary&gt;
/// The supported native types are simple field name - Type tuples.
/// &lt;/summary&gt;
protected void CreateNativeTypes(ISemanticTypeStruct sts, List&lt;Tuple&lt;string, Type&gt;&gt; fieldTypes)
{
  // Create fields for NT's.
  sts.NativeTypes.ForEach(child =&gt;
  {
    Type t = child.GetImplementingType(rsys.SemanticTypeSystem);

    if (t != null)
    {
      fieldTypes.Add(new Tuple&lt;string, Type&gt;(child.Name, t));
    }
    else
    {
      // TODO: The reason for the try-catch is to deal with implementing types we don't support yet, like List&lt;SomeType&gt;
      // For now, we create a stub type.
      fieldTypes.Add(new Tuple&lt;string, Type&gt;(child.Name, typeof(string)));
    }
  });
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> The object <code>dbio</code> 
is an interface supporting the connection and syntax nuances for different 
physical databases such as SQLite, Postgres, SQL Server, etc.</p>
<p>Once created, we can inspect the database for, in this case, a very simple implementation.&nbsp; 
Here's what Postgres says about the table created by the above code:</p>
<pre>CREATE TABLE latlon
(
  id serial NOT NULL,
  latitude double precision,
  longitude double precision,
  CONSTRAINT latlon_pkey PRIMARY KEY (id)
)</pre>
<p>Each of our unit tests drops tables and recreates them to clear out the data 
from previous tests.</p>
<h4>A Simple Non-Unique Key Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; This test verifies that when we insert identical information, we get two 
records back:</p>
<pre>/// &lt;summary&gt;
/// Verifies that a non-unique ST with 2 NT's generates multiple records for the same data.
/// &lt;/summary&gt;
[TestMethod]
public void SimpleNonUniqueInsert()
{
  InitializeSDRTests(() =&gt; InitLatLonNonUnique());

  // Initialize the Semantic Data Receptor with the signal it should be listening to.
  DropTable(&quot;Restaurant&quot;);
  DropTable(&quot;LatLon&quot;);
  sdr.Protocols = &quot;LatLon&quot;;
  sdr.ProtocolsUpdated();

  // Create the signal.
  ICarrier carrier = Helpers.CreateCarrier(rsys, &quot;LatLon&quot;, signal =&gt;
  {
    signal.latitude = 1.0;
    signal.longitude = 2.0;
  });

  // Let's see what the SDR does.
  sdr.ProcessCarrier(carrier);
  IDbConnection conn = sdr.Connection;

  int count;
  IDbCommand cmd = conn.CreateCommand();
  cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);

  // Insert another, identical record. We should now have two records.
  sdr.ProcessCarrier(carrier);
  cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(2, count, &quot;Expected 2 LatLon records.&quot;);

  sdr.Terminate();
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> In the above code, a 
&quot;carrier&quot; is created.&nbsp; Carriers are like little messenger pigeons that are 
used to communicate between receptors.&nbsp; Because the semantic database is 
implemented within a receptor, we have to pretend to send it a message.&nbsp; 
You can review <a href="http://www.higherorderprogramming.com/developers-1-1-2/">
the previous articles on HOPE</a> to learn more about carriers, protocols, and 
signals, but the basic idea here is that we are creating a carrier for the 
protocol &quot;LatLon&quot; (whose semantic structure we defined earlier) and assigning 
values to the native type fields.&nbsp; The semantic engine generates the C# 
code for each semantic structure and instantiates it for us.&nbsp; Taking 
advantage of the <code>dynamic</code> keyword, we can then assign values to the properties
without requiring a C# <code>interface</code> declaration.</p>
<p><img border="0" src="note.png" width="24" height="32">The reason we don't 
explicitly state &quot;insert&quot; somewhere in this carrier is because in the grand 
scheme of things, all we want to do is listen for particular semantic instances 
(protocol-signal), and if we see one, we persist it.&nbsp; The front-end UI 
allows us to choose which semantic types we persist, but the advantage is that 
any &quot;receptor&quot; emitting a particular protocol doesn't care about whether it's 
persisted or not -- basically, we've turned persistence into an optional 
component, decoupling it completely from any other computational units.&nbsp; 
This also means that we can implement different persistence mechanisms, 
traditional RDBMS, graph, even NoSQL, Excel export, etc.</p>
<p><img border="0" src="database.png" width="32" height="32">What's going on 
when we pass in a semantic structure?&nbsp; This triggers the insert/update 
algorithm, though we'll be focusing only on inserts in this article.&nbsp; The 
exposed &quot;API&quot; function sets up some initial state variables and calls a 
recursive method:</p>
<pre>string st = carrier.Protocol.DeclTypeName;

// Get the STS for the carrier's protocol:
ISemanticTypeStruct sts = rsys.SemanticTypeSystem.GetSemanticTypeStruct(st);
Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap = new Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt;();

ProcessSTS(stfkMap, sts, carrier.Signal);</pre>
<p>Structures need to be inserted into the database from the bottom up to ensure 
foreign key integrity.&nbsp; The method <code>ProcessSTS</code>&nbsp; does this 
by drilling down to the lowest structural elements -- the ones that implement 
only native types.&nbsp; The top level function is straight forward, recursing 
into child semantic elements until the semantic element &quot;bottoms out&quot; into just 
native types:</p>
<pre>/// &lt;summary&gt;
/// Drills into any child semantic elements, accumulating foreign keys for each level in the semantic hierarchy.
/// When all children are inserted/updated, the parent can be inserted.
/// &lt;/summary&gt;
protected int ProcessSTS(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal, bool childAsUnique = false)
{
  // Drill into each child ST and assign the return ID to this ST's FK for the child table name.
  ProcessChildren(stfkMap, sts, signal, childAsUnique);

  // Having processed all child ST's, We can now make the same determination of
  // whether the record needs to check for uniqueness, however at this level,
  // we need to write out both ST and any NT values in the current ST structure.
  // This is very similar to an ST without child ST's, but here we also use ST's that are designated as unique to build the composite key.
  int id = ArbitrateUniqueness(stfkMap, sts, signal, childAsUnique);

return id;
}</pre>
<p>When the algorithm bottoms out, the data is checked for unique semantic 
elements and native types, which determines whether to allow duplicates to be 
inserted and whether to perform an update or an insert.&nbsp; </p>
<p>As the algorithm works back up the semantic tree, the id's of the children 
are accumulated so that they can populate the parent's foreign key fields:</p>
<pre>/// &lt;summary&gt;
/// For each child that has a non-null signal, process its children.
/// &lt;/summary&gt;
protected void ProcessChildren(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal, bool childAsUnique)
{
  sts.SemanticElements.ForEach(child =&gt;
  {
    // Get the child signal and STS and check it, returning a new or existing ID for the entry.
    ISemanticTypeStruct childsts = child.Element.Struct; // rsys.SemanticTypeSystem.GetSemanticTypeStruct(child.Name);
    object childSignal = GetChildSignal(signal, child);

    // We don't insert null child signals.
    if (childSignal != null)
    {
      int id = ProcessSTS(stfkMap, childsts, childSignal, (sts.Unique || childAsUnique));
      RegisterForeignKeyID(stfkMap, sts, child, id);
    }
  });
}</pre>
<p>Each child ID is associated with its name (auto-generated by the semantic 
database engine) and its parent semantic element, such that each semantic 
element has a list of 0 or more foreign key relations when all the children have 
been processed:</p>
<pre>/// &lt;summary&gt;
/// Registers a foreign key name and value to be associated with the specified semantic structure, which is used when the ST is inserted
/// after all child elements have been resolved.
/// &lt;/summary&gt;
protected void RegisterForeignKeyID(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, ISemanticElement child, int id)
{
  // Associate the ID to this ST's FK for that child table.
  string fieldName = &quot;FK_&quot; + child.Name + &quot;ID&quot;;
  CreateKeyIfMissing(stfkMap, sts);
  stfkMap[sts].Add(new FKValue(fieldName, id, child.UniqueField));
}
</pre>
<p>The unique native type, semantic element (the foreign key and all child, 
grandchild, etc elements and native types) and semantic structure (all child, 
grandchild, etc elements and native types) is arbitrated by checking various 
flags that are set for the specific semantic structure or by its parent.&nbsp; I 
realize that was a mouthful, so let's look at the code:</p>
<pre>	/// &lt;summary&gt;
/// Based on whether a semantic element is unique or whether the foreign key fields or native types are unique, we determine how to determine uniqueness.
/// We always perform an insert if there is no way to determine whether the record is unique.
/// If it is unique, the ID of the existing record is returned.
/// &lt;/summary&gt;
/// &lt;param name=&quot;stfkMap&quot;&gt;&lt;/param&gt;
protected int ArbitrateUniqueness(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal, bool childAsUnique)
{
  int id = -1;

  if (sts.Unique || childAsUnique)
  {
    // All FK's and NT's of this ST are considered part of the composite key.
    // Get all NT's specifically for this ST (no recursive drilldown)
    List&lt;IFullyQualifiedNativeType&gt; fieldValues = rsys.SemanticTypeSystem.GetFullyQualifiedNativeTypeValues(signal, sts.DeclTypeName, false);
    id = InsertIfRecordDoesntExist(stfkMap, sts, signal, fieldValues, true);
  }
  else if (sts.SemanticElements.Any(se =&gt; se.UniqueField) || sts.NativeTypes.Any(nt =&gt; nt.UniqueField))
  {
    // Get only unique NT's specifically for this ST (no recursive drilldown)
    // Note that a unique semantic element will automatically set the unique field for its native type children, subchildren, etc.
    List&lt;IFullyQualifiedNativeType&gt; fieldValues = rsys.SemanticTypeSystem.GetFullyQualifiedNativeTypeValues(signal, sts.DeclTypeName, false).Where(fqnt =&gt; fqnt.NativeType.UniqueField).ToList();
    id = InsertIfRecordDoesntExist(stfkMap, sts, signal, fieldValues, true);
  }
  else
  {
    // No SE's or NT's are unique, so just insert the ST, as we cannot make a determination regarding uniqueness.
    id = Insert(stfkMap, sts, signal);
  }

  return id;
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> Not obvious is the 
fact that GetFullyQualifiedNativeTypeValues is returning structures that carry 
forward the parent element's uniqueness flag.&nbsp; </p>
<p>We have three states:</p>
<ol>
	<li>The structure or a parent structure is flagged as unique.&nbsp; This 
	treats all foreign key and native type fields as comprising the composite 
	unique key.</li>
	<li>One or more child elements (implemented as a foreign key) is unique or 
	one or more native type elements is unique.&nbsp; The unique composite key 
	consists exclusively of the unique foreign key and native type fields.</li>
	<li>There is no unique key.&nbsp; In this case, the structure is always 
	inserted.</li>
</ol>
<p>Once we have some unique fields, we test to see whether it's unique and, if 
so insert it:</p>
<pre>/// &lt;summary&gt;
/// Insert the record if it doesn't exist.
/// &lt;/summary&gt;
protected int InsertIfRecordDoesntExist(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal, List&lt;IFullyQualifiedNativeType&gt; fieldValues, bool childAsUnique)
{
  int id = -1;
  bool exists = QueryUniqueness(stfkMap, sts, signal, fieldValues, out id, true);

  if (!exists)
  {
    id = Insert(stfkMap, sts, signal);
  }

  return id;
}</pre>
<p>The new record's primary key ID is returned or the existing ID is returned.</p>
<pre>/// &lt;summary&gt;
/// Build and execute a select statement that determines if the record, based on a composite key, already exists.
/// If so, return the ID of the record.
/// &lt;/summary&gt;
protected bool QueryUniqueness(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal, List&lt;IFullyQualifiedNativeType&gt; uniqueFieldValues, out int id, bool allFKs = false)
{
  id = -1;
  bool ret = false;
  List&lt;FKValue&gt; fkValues;
  bool hasFKValues = stfkMap.TryGetValue(sts, out fkValues);
  StringBuilder sb = BuildUniqueQueryStatement(hasFKValues, fkValues, sts, uniqueFieldValues, allFKs); 
  IDbCommand cmd = AddParametersToCommand(uniqueFieldValues, hasFKValues, fkValues, allFKs);
  cmd.CommandText = sb.ToString();
  LogSqlStatement(cmd.CommandText);

  object oid = cmd.ExecuteScalar();
  ret = (oid != null);

  if (ret)
  {
    id = Convert.ToInt32(oid);
  }

  return ret;
}</pre>
<p>And finally, if an insert is required, we have this rather unwieldy piece of 
code to actually perform the insert:</p>
<pre>protected int Insert(Dictionary&lt;ISemanticTypeStruct, List&lt;FKValue&gt;&gt; stfkMap, ISemanticTypeStruct sts, object signal)
{
  // Get native types to insert:
  List&lt;IFullyQualifiedNativeType&gt; ntFieldValues = rsys.SemanticTypeSystem.GetFullyQualifiedNativeTypeValues(signal, sts.DeclTypeName, false);
  StringBuilder sb = new StringBuilder(&quot;insert into &quot; + sts.DeclTypeName + &quot; (&quot;);
  sb.Append(String.Join(&quot;, &quot;, ntFieldValues.Select(f =&gt; f.Name)));

  // Get ST's to insert as FK_ID's:
  List&lt;FKValue&gt; fkValues;
  bool hasFKValues = stfkMap.TryGetValue(sts, out fkValues);

  if (hasFKValues &amp;&amp; fkValues.Count &gt; 0)
  {
    // Join in the FK_ID field names.
    if (ntFieldValues.Count &gt; 0) sb.Append(&quot;, &quot;);
    sb.Append(string.Join(&quot;, &quot;, fkValues.Select(fkv =&gt; fkv.FieldName)));
  }

  // Setup NT field values:
  sb.Append(&quot;) values (&quot;);
  sb.Append(String.Join(&quot;, &quot;, ntFieldValues.Select(f =&gt; &quot;@&quot; + f.Name)));

  // Setup ST FK parameters:
  if (hasFKValues &amp;&amp; fkValues.Count &gt; 0)
  {
    if (ntFieldValues.Count &gt; 0) sb.Append(&quot;, &quot;);
    sb.Append(string.Join(&quot;, &quot;, fkValues.Select(fkv =&gt; &quot;@&quot; + fkv.FieldName)));
  }

  sb.Append(&quot;)&quot;);
  IDbCommand cmd = dbio.CreateCommand();

  // Assign NT values:
  ntFieldValues.ForEach(fv =&gt; cmd.Parameters.Add(dbio.CreateParameter(fv.Name, fv.Value)));

  // Assign FK values:
  if (hasFKValues &amp;&amp; fkValues.Count &gt; 0)
  {
    fkValues.ForEach(fkv =&gt; cmd.Parameters.Add(dbio.CreateParameter(fkv.FieldName, fkv.ID)));
  }

  cmd.CommandText = sb.ToString();
  LogSqlStatement(cmd.CommandText);
  cmd.ExecuteNonQuery();

  int id = dbio.GetLastID(sts.DeclTypeName);

  return id;
}</pre>
<h4>A Simple Unique Key Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; This test verifies that when we 
attempt to insert two identical records, the semantic database detects this, 
based on our semantic structure configuration, and ignores the second insert 
because it's a duplicate record.</p>
<p>Recall how the non-unique LatLon semantic structure was initialized:</p>
<pre>protected void InitLatLonNonUnique()
{
  SemanticTypeStruct sts = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs);
  Helpers.CreateNativeType(sts, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(sts, &quot;longitude&quot;, &quot;double&quot;, false);
}</pre>
<p>In this unit test, we initialize the structure slightly differently:</p>
<pre>protected void InitLatLonUniqueFields()
{
SemanticTypeStruct sts = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs);
Helpers.CreateNativeType(sts, &quot;latitude&quot;, &quot;double&quot;, <font color="#FF0000"><b>true</b></font>);
Helpers.CreateNativeType(sts, &quot;longitude&quot;, &quot;double&quot;, <font color="#FF0000"><b>true</b></font>);
}<b>
);
</b>  Helpers.CreateNativeType(sts, &quot;longitude&quot;, &quot;double&quot;, true);
}</pre>
<p>Notice in this structure, we are declaring that the native type fields are 
both unique.&nbsp; This composite key comprises the unique fields, and we see 
that the semantic database ends up inserting only one record.</p>
<h4>A Simple Unique Structure Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; Again, this test verifies that when we 
attempt to insert two identical records, the semantic database detects this, 
based on our semantic structure configuration, and ignores the second insert 
because it's a duplicate record.&nbsp; In this case though, it is the semantic 
structure itself that is flagged as unique:</p>
<pre>protected void InitLatLonUniqueST()
{
  SemanticTypeStruct sts = Helpers.CreateSemanticType(&quot;LatLon&quot;, <font color="#FF0000"><b>true</b></font>, decls, structs);
  Helpers.CreateNativeType(sts, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(sts, &quot;longitude&quot;, &quot;double&quot;, false);
}</pre>
<p>Here we're testing (in a simple way) that if a structure is declared as 
unique, then we don't have to bother setting any native type fields <i>anywhere 
in the hierarchy from here on</i> as unique.</p>
<h4>Two-Level Non-Unique Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; Here we do 
something a bit more interesting -- we're going create a simple two-level 
structure: a parent &quot;Restaurant&quot; and a child &quot;LatLon&quot;, and verify that we get 
two records in both the Restaurant and LatLon tables.&nbsp; </p>
<p>First, let's look at the initialization of the semantic structure:</p>
<pre>protected void InitRestaurantLatLonNonUnique()
{
  SemanticTypeStruct stsRest = Helpers.CreateSemanticType(&quot;Restaurant&quot;, false, decls, structs);
  SemanticTypeStruct stsLatLon = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs);
  Helpers.CreateNativeType(stsLatLon, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(stsLatLon, &quot;longitude&quot;, &quot;double&quot;, false);
  Helpers.CreateSemanticElement(stsRest, &quot;LatLon&quot;, false);
}</pre>
<p>We see that &quot;Restaurant&quot; has a &quot;LatLon&quot; element which is comprised of two 
native types, &quot;latitude&quot; and &quot;longitude&quot;.&nbsp; Notice that &quot;Restaurant&quot; doesn't 
have any native types itself -- we don't really need or want any for this 
particular test -- we want to start simply.</p>
<p><img border="0" src="database.png" width="32" height="32">On the database 
side, the semantic database creates the following tables (as described by 
Postgres):</p>
<pre>CREATE TABLE restaurant
(
  id serial NOT NULL,
  fk_latlonid bigint,
  CONSTRAINT restaurant_pkey PRIMARY KEY (id),
  CONSTRAINT restaurant_fk_latlonid_fkey FOREIGN KEY (fk_latlonid)
  REFERENCES latlon (id) MATCH SIMPLE
  ON UPDATE NO ACTION ON DELETE NO ACTION
)</pre>
<p>Notice the foreign key to the LatLon table (annoyingly, Postgres turns all 
tables and fields into lowercase).</p>
<p>The LatLon table hasn't changed:</p>
<pre>CREATE TABLE latlon
(
id serial NOT NULL,
latitude double precision,
longitude double precision,
CONSTRAINT latlon_pkey PRIMARY KEY (id)
)</pre>
<p>This unit test initializes the semantic structure slightly differently now 
because LatLon is an element of Restaurant:</p>
<pre>[TestMethod]
public void TwoLevelNonUniqueSTInsert()
{
  InitializeSDRTests(() =&gt; InitRestaurantLatLonNonUnique());

  // Initialize the Semantic Data Receptor with the signal it should be listening to.
  DropTable(&quot;Restaurant&quot;);
  DropTable(&quot;LatLon&quot;);
  sdr.Protocols = &quot;LatLon; Restaurant&quot;;
  sdr.ProtocolsUpdated();

  // Create the signal.
  ICarrier carrier = Helpers.CreateCarrier(rsys, &quot;Restaurant&quot;, signal =&gt;
  {
<font color="#FF0000"><b>    signal.LatLon.latitude = 1.0;
    signal.LatLon.longitude = 2.0;
</b></font>  });

  // Let's see what the SDR does.
  sdr.ProcessCarrier(carrier);
  IDbConnection conn = sdr.Connection;

  int count;
  IDbCommand cmd = conn.CreateCommand();
  cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
  cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(1, count, &quot;Expected 1 Restaurant record.&quot;);

  // Insert another, identical record. We should still have one record.
  sdr.ProcessCarrier(carrier);
  cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(2, count, &quot;Expected 2 LatLon record.&quot;);
  cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
  count = Convert.ToInt32(cmd.ExecuteScalar());
  Assert.AreEqual(2, count, &quot;Expected 2 Restaurant records.&quot;);

  sdr.Terminate();
}</pre>
<h4>Two-Level Unique Structure Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; Next, we 
want to see what happens when we create the LatLon structure, indicating that it 
is unique:</p>
<pre>protected void InitRestaurantLatLonUniqueChildST()
{
  SemanticTypeStruct stsRest = Helpers.CreateSemanticType(&quot;Restaurant&quot;, false, decls, structs);
  SemanticTypeStruct stsLatLon = Helpers.CreateSemanticType(&quot;LatLon&quot;, <font color="#FF0000"><b>true</b></font>, decls, structs); // child ST LatLon is declared to be unique.
  Helpers.CreateNativeType(stsLatLon, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(stsLatLon, &quot;longitude&quot;, &quot;double&quot;, false);
  Helpers.CreateSemanticElement(stsRest, &quot;LatLon&quot;, false); // The element LatLon in Restaurant is NOT unique.
}</pre>
<p>As expected, when we attempt to insert two duplicate records, that LatLon 
structure is inserted only once and we get two Restaurant records pointing to 
the same LatLon record:</p>
<pre>int count;
IDbCommand cmd = conn.CreateCommand();
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 Restaurant record.&quot;);

// Insert another, identical record. We should still have one record.
sdr.ProcessCarrier(carrier);
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(2, count, &quot;Expected 2 Restaurant records.&quot;);</pre>
<h4>Two-Level Unique Element Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; A variation 
on this theme is creating the Restaurant-LatLon structure such that the LatLon
<i>element</i> of the Restaurant structure is declared unique.&nbsp; In concrete 
terms, this tells the semantic database that the foreign key field &quot;fk_latlonid&quot; 
is a unique field.&nbsp; We initialize the structure in code like this:</p>
<pre>protected void InitRestaurantLatLonUniqueParentSTElement()
{
  SemanticTypeStruct stsRest = Helpers.CreateSemanticType(&quot;Restaurant&quot;, false, decls, structs);
  SemanticTypeStruct stsLatLon = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs); // child ST LatLon is declared to NOT be unique.
  Helpers.CreateNativeType(stsLatLon, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(stsLatLon, &quot;longitude&quot;, &quot;double&quot;, false);
  Helpers.CreateSemanticElement(stsRest, &quot;LatLon&quot;, <font color="#FF0000"><b>true</b></font>); // The element LatLon in Restaurant is unique.
}</pre>
<p>Here's our test (the earlier part of the test code is the same as in the 
previous cases):</p>
<pre>int count;
IDbCommand cmd = conn.CreateCommand();
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 Restaurant record.&quot;);

// Insert another, identical record. We should have two records.
sdr.ProcessCarrier(carrier);
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(2, count, &quot;Expected 2 LatLon records.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(2, count, &quot;Expected 2 Restaurant records.&quot;);</pre>
<p>Because only the foreign key is unique, we will be inserting two LatLon 
records, as there are no fields declared unique in LatLon.&nbsp; Because this 
returns a new ID, the foreign key field is not unique, causing a second entry in 
the Restaurant table.</p>
<h4>Two-Level Unique Element <i>and Structure </i>Insert Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; Finally, we 
test the combination where both the Restaurant's <i>element</i> LatLon (ie, it's 
foreign key) <i>and</i> the LatLon structure itself are unique.&nbsp; Here's how 
we configure the semantic structure:</p>
<pre>protected void InitRestaurantUniqueLatLonAndParentSTElement()
{
  SemanticTypeStruct stsRest = Helpers.CreateSemanticType(&quot;Restaurant&quot;, false, decls, structs);
  SemanticTypeStruct stsLatLon = Helpers.CreateSemanticType(&quot;LatLon&quot;, <font color="#FF0000"><b>true</b></font>, decls, structs); 
  Helpers.CreateNativeType(stsLatLon, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(stsLatLon, &quot;longitude&quot;, &quot;double&quot;, false);
  Helpers.CreateSemanticElement(stsRest, &quot;LatLon&quot;, <font color="#FF0000"><b>true</b></font>); // The element LatLon in Restaurant is unique.
}</pre>
<p>Now we see that, because the structure LatLon is unique <i>and</i> the LatLon 
element in Restaurant is unique (implemented as the foreign key) we get one 
Restaurant record and one LatLon record when we attempt to insert two identical 
records:</p>
<pre>int count;
IDbCommand cmd = conn.CreateCommand();
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 Restaurant record.&quot;);

// Insert another, identical record. We should still have one record.
sdr.ProcessCarrier(carrier);
cmd.CommandText = &quot;SELECT count(*) from LatLon&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 LatLon record.&quot;);
cmd.CommandText = &quot;SELECT count(*) from Restaurant&quot;;
count = Convert.ToInt32(cmd.ExecuteScalar());
Assert.AreEqual(1, count, &quot;Expected 1 Restaurant record.&quot;);</pre>
<p><img border="0" src="quiz.png" width="47" height="64"> Since this is all very 
complicated, let's test your comprehension.&nbsp; What happens when the semantic 
structure is declared like this:</p>
<pre>protected void InitRestaurantUniqueLatLonAndParentSTElement()
{
  SemanticTypeStruct stsRest = Helpers.CreateSemanticType(&quot;Restaurant&quot;, <font color="#FF0000"><b>true</b></font>, decls, structs);
  SemanticTypeStruct stsLatLon = Helpers.CreateSemanticType(&quot;LatLon&quot;, false, decls, structs); 
  Helpers.CreateNativeType(stsLatLon, &quot;latitude&quot;, &quot;double&quot;, false);
  Helpers.CreateNativeType(stsLatLon, &quot;longitude&quot;, &quot;double&quot;, false);
  Helpers.CreateSemanticElement(stsRest, &quot;LatLon&quot;, true); // The element LatLon in Restaurant is unique.
}</pre>
<p>Yes indeed, because the Restaurant structure is itself declared as unique, 
every child element inherits its parent's uniqueness, and again we will insert 
only one actual record for two or more attempts of a duplicate semantic 
structure value.</p>
<h3>A Simple Query Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> If you thought 
inserting data was complicated, getting it back out of the database is even more 
complicated because of the inferences that the semantic database makes regarding 
how to join to disparate semantic structures.&nbsp; Querying consists of:</p>
<ul>
	<li>Determining the native type fields</li>
<li>Build the list of joins required to drill down into child elements</li>
	<li>Resolve physical table and field names in the order by clause</li>
<li>Resolve physical table and field names in the where clause (currently not 
implemented)</li>
	<li>Add the database-specific implementation of a row return limit</li>
<li>In a multi-structure join, infer the linkages between structures and 
implement them as additional table joins</li>
	<li>Execute the query</li>
<li>Hydrate semantic instances with the data from each returned row</li>
</ul>
<p>Let's start with a basic 
single structure query:</p>
<pre>[TestMethod]
public void SimpleQuery()
{
  InitializeSDRTests(() =&gt; InitLatLonNonUnique());

  // Initialize the Semantic Data Receptor with the signal it should be listening to.
  DropTable(&quot;Restaurant&quot;); // Dependent table we have to remove first.
  DropTable(&quot;LatLon&quot;);
  sdr.Protocols = &quot;LatLon&quot;;
  sdr.ProtocolsUpdated();
  sdr.UnitTesting = true;

  // Create the signal.
  ICarrier latLonCarrier = Helpers.CreateCarrier(rsys, &quot;LatLon&quot;, signal =&gt;
  {
    signal.latitude = 1.0;
    signal.longitude = 2.0;
  });

  sdr.ProcessCarrier(latLonCarrier);

  // Create the query
  ICarrier queryCarrier = Helpers.CreateCarrier(rsys, &quot;Query&quot;, signal =&gt;
  {
    signal.QueryText = &quot;LatLon&quot;;
  });

  sdr.ProcessCarrier(queryCarrier);
  List&lt;QueuedCarrierAction&gt; queuedCarriers = rsys.QueuedCarriers;
  Assert.AreEqual(1, queuedCarriers.Count, &quot;Expected one signal to be returned.&quot;);
  dynamic retSignal = queuedCarriers[0].Carrier.Signal;
  Assert.AreEqual(1.0, retSignal.latitude, &quot;Wrong data for latitude.&quot;);
  Assert.AreEqual(2.0, retSignal.longitude, &quot;Wrong data for longitude.&quot;);
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> Because we're using 
the HOPE architecture, there is actually no receiving carrier for the resulting 
record, so we inspect the queue, which is simpler than adding the necessary 
scaffolding in our unit tests to receive the carrier.</p>
<p><img border="0" src="database.png" width="32" height="32"> The 
single-structure query implementation is basically what you would expect:</p>
<pre>protected void QueryDatabase(string query)
{
  string maxRecords = null;
  List&lt;string&gt; types;
  List&lt;string&gt; orderBy;

  Preprocess(query, out maxRecords, out types, out orderBy);

  // We only have one protocol to query, so we can create the protocol directly since it's already defined.
  if (types.Count() == 1)
  {
    string protocol = types[0];
    AddEmitProtocol(protocol); // identical protocols are ignored.
    ISemanticTypeStruct sts = rsys.SemanticTypeSystem.GetSemanticTypeStruct(protocol);
    List&lt;object&gt; signals = QueryType(protocol, String.Empty, orderBy, maxRecords);
    EmitSignals(signals, sts);
  }
  else ...</pre>
<p><img border="0" src="note.png" width="24" height="32"> Again, because the 
semantic database is actually a receptor, any newly encountered protocol is 
added to the list of protocols that the database emits.&nbsp; Hence the line 
<code>AddEmitProtocol</code>.</p>
<p>The method <code>QueryType</code> puts all the pieces together to execute the 
query:</p>
<pre>/// &lt;summary&gt;
/// Return a list of objects that represents the semantic element instances (signals) in the resulting query set.
/// &lt;/summary&gt;
protected List&lt;object&gt; QueryType(string protocol, string where, List&lt;string&gt; orderBy, string maxRecords)
{
  // We build the query by recursing through the semantic structure.
  ISemanticTypeStruct sts = rsys.SemanticTypeSystem.GetSemanticTypeStruct(protocol);
  List&lt;string&gt; fields = new List&lt;string&gt;();
  List&lt;string&gt; joins = new List&lt;string&gt;();
  Dictionary&lt;ISemanticTypeStruct, int&gt; structureUseCounts = new Dictionary&lt;ISemanticTypeStruct, int&gt;();
  List&lt;Tuple&lt;string, string&gt;&gt; fqntAliases = new List&lt;Tuple&lt;string, string&gt;&gt;();

  BuildQuery(sts, fields, joins, structureUseCounts, sts.DeclTypeName, fqntAliases);
  string sqlQuery = CreateSqlStatement(sts, fields, joins, fqntAliases, where, orderBy, maxRecords);

  List&lt;object&gt; ret = PopulateSignals(sqlQuery, sts);

  return ret;
}</pre>
<p>Very important in this process is the recursive <code>BuildQuery</code>, which traverses 
the semantic structure, following child elements and creating the necessary 
joins as well as picking up any native types along the way:</p>
<pre>/// &lt;summary&gt;
/// Recurses the semantic structure to generate the native type fields and the semantic element joins.
/// fqntAliases -- fully qualified native type and it's actual alias in the field list.
/// &lt;/summary&gt;
protected void BuildQuery(ISemanticTypeStruct sts, List&lt;string&gt; fields, List&lt;string&gt; joins, Dictionary&lt;ISemanticTypeStruct, int&gt; structureUseCounts, string fqn, List&lt;Tuple&lt;string, string&gt;&gt; fqntAliases)
{
  // Add native type fields.
  string parentName = GetUseName(sts, structureUseCounts);
  sts.NativeTypes.ForEach(nt =&gt;
  {
    string qualifiedFieldName = fqn + &quot;.&quot; + nt.Name;
    string qualifiedAliasFieldName = parentName + &quot;.&quot; + nt.Name;
    fields.Add(qualifiedAliasFieldName);
    fqntAliases.Add(new Tuple&lt;string, string&gt;(qualifiedFieldName, qualifiedAliasFieldName));
  });

  sts.SemanticElements.ForEach(child =&gt;
  {
    ISemanticTypeStruct childsts = child.Element.Struct; // rsys.SemanticTypeSystem.GetSemanticTypeStruct(child.Name);
    IncrementUseCount(childsts, structureUseCounts);
    string asChildName = GetUseName(childsts, structureUseCounts);
    joins.Add(&quot;left join &quot; + childsts.DeclTypeName + &quot; as &quot; + asChildName + &quot; on &quot; + asChildName + &quot;.ID = &quot; + parentName + &quot;.FK_&quot; + childsts.DeclTypeName + &quot;ID&quot;);
    BuildQuery(childsts, fields, joins, structureUseCounts, fqn+&quot;.&quot;+childsts.DeclTypeName, fqntAliases);
  });
}</pre>
<p>Once that's done, the actual SQL select statement can be created:</p>
<pre>protected string CreateSqlStatement(ISemanticTypeStruct sts, List&lt;string&gt; fields, List&lt;string&gt; joins, List&lt;Tuple&lt;string, string&gt;&gt; fqntAliases, string where, List&lt;string&gt; orderBy, string maxRecords)
{
  // CRLF for pretty inspection.
  string sqlQuery = &quot;select &quot; + String.Join(&quot;, &quot;, fields) + &quot; \r\nfrom &quot; + sts.DeclTypeName + &quot; \r\n&quot; + String.Join(&quot; \r\n&quot;, joins);
  sqlQuery = sqlQuery + &quot; &quot; + ParseOrderBy(orderBy, fqntAliases);
  sqlQuery = dbio.AddLimitClause(sqlQuery, maxRecords);

  return sqlQuery;
}</pre>
<p>Once we've acquired the reader, we can iterate through the records and create 
the signals to be emitted:</p>
<pre>protected List&lt;object&gt; PopulateSignals(string sqlQuery, ISemanticTypeStruct sts)
{
  List&lt;object&gt; ret = new List&lt;object&gt;();
  IDataReader reader = AcquireReader(sqlQuery);

  while (reader.Read())
  {
    object outsignal = rsys.SemanticTypeSystem.Create(sts.DeclTypeName);
    int counter = 0; // For a single table join, counter is always 0.
    // Populate the signal with the columns in each record read.
    Populate(sts, outsignal, reader, ref counter);
    ret.Add(outsignal);
  }

  reader.Close();

  return ret;
}</pre>
<p>The actual population of the signal's fields is again recursive and dependent 
upon the same order in which fields were generated for the query statement.&nbsp; 
Here we are using reflection to set the values as we drill into the semantic 
structure:</p>
<pre>/// &lt;summary&gt;
/// Recursively populates the values into the signal. The recursion algorithm here must match exactly the same
/// form as the recursion algorithm in BuildQuery, as the correlation between field names and their occurrance
/// in the semantic structure is relied upon. For now at least.
/// Returns true if there are any non-null NT valus.
/// &lt;/summary&gt;
protected bool Populate(ISemanticTypeStruct sts, object signal, IDataReader reader, ref int parmNumber)
{
  List&lt;object&gt; vals = new List&lt;object&gt;();
  bool anyNonNull = false;

  for (int i = 0; i &lt; sts.NativeTypes.Count; i++)
  {
    vals.Add(reader[parmNumber++]);
  }

  // Add native type fields. Use a foreach loop because ref types can't be used in lambda expressions.
  sts.NativeTypes.ForEachWithIndex((nt, idx) =&gt;
  {
    object val = vals[idx];

    if (val != DBNull.Value)
    {
      Assert.TryCatch(() =&gt; nt.SetValue(rsys.SemanticTypeSystem, signal, val), (ex) =&gt; EmitException(ex));
      anyNonNull = true;
    }
  });

  foreach (ISemanticElement child in sts.SemanticElements)
  {
    ISemanticTypeStruct childsts = child.Element.Struct;
    PropertyInfo piSub = signal.GetType().GetProperty(child.Name);
    object childSignal = piSub.GetValue(signal);
    anyNonNull |= Populate(childsts, childSignal, reader, ref parmNumber);
  }

  return anyNonNull;
}</pre>
<p><img border="0" src="note.png" width="24" height="32">&nbsp; In the single 
structure query, we don't really care whether there are any non-null fields.&nbsp; 
The return value of the Populate method is however used when working with 
multi-structure queries, as all-null fields for a structure sets the structure 
to null.&nbsp; Also, <code>parmNumber</code> is again something that comes 
into play in a multi-structure query.</p>
<h3>Alias Query Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> This test does a 
simple check that table and field name aliases are used.&nbsp; The semantic 
structure is set up as follows:</p>
<pre>protected void InitPersonStruct()
{
  SemanticTypeStruct stsText = Helpers.CreateSemanticType(&quot;Text&quot;, false, decls, structs);
  Helpers.CreateNativeType(stsText, &quot;Value&quot;, &quot;string&quot;, false);

  SemanticTypeStruct stsFirstName = Helpers.CreateSemanticType(&quot;FirstName&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsFirstName, &quot;Text&quot;, false);

  SemanticTypeStruct stsLastName = Helpers.CreateSemanticType(&quot;LastName&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsLastName, &quot;Text&quot;, false);

  SemanticTypeStruct stsPerson = Helpers.CreateSemanticType(&quot;Person&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsPerson, &quot;LastName&quot;, false);
  Helpers.CreateSemanticElement(stsPerson, &quot;FirstName&quot;, false);
}</pre>
<p>Here, Person consists of FirstName and LastName, both of which reference the 
Text structure.&nbsp; This requires two joins to the Text table which means the 
table has to be aliased.&nbsp; The field name, being the same, must be aliased 
as well.&nbsp; </p>
<p><img border="0" src="database.png" width="32" height="32"> In the semantic 
database, this is accomplished by keeping track of the table usage and 
incrementing a counter for each usage:</p>
<pre>/// &lt;summary&gt;
/// Append the use counter if it exists.
/// &lt;/summary&gt;
protected string GetUseName(ISemanticTypeStruct sts, Dictionary&lt;ISemanticTypeStruct, int&gt; structureUseCounts)
{
  int count;
  string ret = sts.DeclTypeName;

  if (structureUseCounts.TryGetValue(sts, out count))
  {
    ret = ret + count;
  }

  return ret;
}</pre>
<p>The resulting query looks like this:</p>
<pre>select <font color="#FF0000"><b>Text1</b></font>.Value, <font color="#FF0000"><b>Text2</b></font>.Value 
from Person 
left join LastName as <font color="#FF0000"><b>LastName1</b></font> on LastName1.ID = Person.FK_LastNameID 
left join Text as <font color="#FF0000"><b>Text1</b></font> on Text1.ID = LastName1.FK_TextID 
left join FirstName as <font color="#FF0000"><b>FirstName1</b></font> on FirstName1.ID = Person.FK_FirstNameID 
left join Text as <font color="#FF0000"><b>Text2</b></font> on Text2.ID = FirstName1.FK_TextID </pre>
<p>Notice the &quot;as&quot; statements.&nbsp; For convenience, every table is aliased.&nbsp; 
This is essential for multi-structure joins.</p>
<h3>Unique Key Join</h3>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; There are 
three ways to join structures: by their unique key fields, the structure being 
declared unique, or by a structure's unique elements.&nbsp; The latter two 
resolve to unique key fields, but still requires testing (the test after this 
one.)&nbsp; Here, we test that a shared structure, which is declared as unique, 
allows the semantic database to infer that the two parent structures can be 
joined.&nbsp; The structures are defined like this:</p>
<pre>protected void InitFeedUrlWithUniqueStruct()
{
  SemanticTypeStruct stsUrl = Helpers.CreateSemanticType(&quot;Url&quot;, <font color="#FF0000"><b>true</b></font>, decls, structs);
  Helpers.CreateNativeType(stsUrl, &quot;Value&quot;, &quot;string&quot;, false);

  SemanticTypeStruct stsVisited = Helpers.CreateSemanticType(&quot;Visited&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsVisited, &quot;Url&quot;, false);
  Helpers.CreateNativeType(stsVisited, &quot;Count&quot;, &quot;int&quot;, false);

  SemanticTypeStruct stsFeedUrl = Helpers.CreateSemanticType(&quot;RSSFeedUrl&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsFeedUrl, &quot;Url&quot;, false);
}</pre>
<p>A common structure, Url, is created as being unique.&nbsp; Both the Visited 
and RSSFeedURl structures reference Url.&nbsp; </p>
<p>The unit test sets up two &quot;feed&quot; entries:</p>
<ul>
	<li><a href="http://localhost">http://localhost</a></li>
	<li><a href="http://www.codeproject.com">http://www.codeproject.com</a></li>
</ul>
<p>However, the visited only references <a href="http://localhost">
http://localhost</a> (sorry Code Project!)</p>
<pre>protected void TwoStructureJoinTest()
{
  DropTable(&quot;Url&quot;);
  DropTable(&quot;Visited&quot;);
  DropTable(&quot;RSSFeedUrl&quot;);

  sdr.Protocols = &quot;RSSFeedUrl; Visited&quot;;
  sdr.ProtocolsUpdated();
  sdr.UnitTesting = true;

  // The schema defines that:
  // URL is a unique structure
  // RSSFeedUrl.Url is unique (no duplicates pointing to the same Url)
  // Visited.Url is unique (no duplicates pointing to the same Url)

  ICarrier feedUrlCarrier1 = Helpers.CreateCarrier(rsys, &quot;RSSFeedUrl&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://localhost&quot;;
  });

  // A URL we will not be joining on because we don't have a Visited record.
  ICarrier feedUrlCarrier2 = Helpers.CreateCarrier(rsys, &quot;RSSFeedUrl&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://www.codeproject.com&quot;;
  });

  ICarrier visitedCarrier = Helpers.CreateCarrier(rsys, &quot;Visited&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://localhost&quot;;
    signal.Count = 1; // non-zero value to make sure that we're not getting a default value back.
  });

  sdr.ProcessCarrier(feedUrlCarrier1);
  sdr.ProcessCarrier(feedUrlCarrier2);
  sdr.ProcessCarrier(visitedCarrier);

  // Create the query
  ICarrier queryCarrier = Helpers.CreateCarrier(rsys, &quot;Query&quot;, signal =&gt;
  {
    // *** The order here is important, because the second join will be a left join ***
    // TODO: This needs to be exposed to the user somehow.
    signal.QueryText = &quot;RSSFeedUrl, Visited&quot;;
  });

  sdr.ProcessCarrier(queryCarrier);
  List&lt;QueuedCarrierAction&gt; queuedCarriers = rsys.QueuedCarriers;
  Assert.AreEqual(2, queuedCarriers.Count, &quot;Expected two signals to be returned.&quot;);

  // The result, using a left join, is:

  // &quot;http://localhost&quot;; 1; &quot;http://localhost&quot;
  // &quot;http://www.codeproject.com&quot;; ; &quot;&quot; &lt;-- notice the Visited portion is null!

  // This is a new ST that isn't defined in our schema.
  dynamic retSignal = queuedCarriers[0].Carrier.Signal;
  Assert.AreEqual(&quot;http://localhost&quot;, retSignal.RSSFeedUrl.Url.Value, &quot;Unexpected URL value.&quot;);
  Assert.AreEqual(1, retSignal.Visited.Count);

  retSignal = queuedCarriers[1].Carrier.Signal;
  Assert.AreEqual(&quot;http://www.codeproject.com&quot;, retSignal.RSSFeedUrl.Url.Value, &quot;Unexpected URL value.&quot;);
  Assert.AreEqual(null, retSignal.Visited);
}</pre>
<p><img border="0" src="database.png" width="32" height="32"> We see from the 
query how it is joining the two tables:</p>
<pre>select Url1.Value, Visited.Count, Url2.Value 
from RSSFeedUrl 
left join Url as Url1 on Url1.ID = RSSFeedUrl.FK_UrlID 
left join Visited on Visited.FK_UrlID = RSSFeedUrl.FK_UrlID 
left join Url as Url2 on Url2.ID = Visited.FK_UrlID </pre>
<p>And note how the data is returned:</p>
<p><img border="0" src="query1.png" width="517" height="120"></p>
<p><img border="0" src="note.png" width="24" height="32"> The second row shows 
us the we do not have an associated Visited record for
<a href="http://www.codeproject.com">http://www.codeproject.com</a>.&nbsp; 
Because the Visited structure's fields are all null, the semantic database sets 
the instance to null, which is tested here:</p>
<pre>  retSignal = queuedCarriers[1].Carrier.Signal;
  Assert.AreEqual(&quot;http://www.codeproject.com&quot;, retSignal.RSSFeedUrl.Url.Value, &quot;Unexpected URL value.&quot;);
  <font color="#FF0000"><b>Assert.AreEqual(null, retSignal.Visited);</b></font></pre>
<p><img border="0" src="note.png" width="24" height="32"> Also observe that the 
structure returned has been created at runtime by the semantic database.&nbsp; 
The returning signal consists of a root semantic type whose elements are the 
joined structures.&nbsp; Thus, in the above query, we get back the following 
structure:</p>
<p><img border="0" src="query2.png" width="288" height="84"></p>
<p>Or, as I prefer to diagram semantic structures so that the native types are 
all at the top:</p>
<p><img border="0" src="query3.png" width="288" height="216"></p>
<p><img border="0" src="database.png" width="32" height="32"> What happens we 
try to join multiple semantic structures?</p>
<p>First, we need to discover the correct join order, such that tables are 
declared in the SQL join before they are referenced.&nbsp; While this is not a 
requirement for all database engines, I have noted that SQLite is definitely not 
happy if it sees a reference to table that hasn't been declared in a join yet.&nbsp; 
So, we can now begin walking through the code in this path:</p>
<pre>else if (types.Count() &gt; 1)
{
  // First we need to find common structures between each of the specified structures.
  Dictionary&lt;string, List&lt;Tuple&lt;ISemanticTypeStruct, ISemanticTypeStruct&gt;&gt;&gt; stSemanticTypes = new Dictionary&lt;string, List&lt;Tuple&lt;ISemanticTypeStruct, ISemanticTypeStruct&gt;&gt;&gt;();
  Dictionary&lt;TypeIntersection, List&lt;ISemanticTypeStruct&gt;&gt; typeIntersectionStructs = new Dictionary&lt;TypeIntersection, List&lt;ISemanticTypeStruct&gt;&gt;();
  Dictionary&lt;ISemanticTypeStruct, int&gt; structureUseCounts = new Dictionary&lt;ISemanticTypeStruct, int&gt;();

  List&lt;TypeIntersection&gt; joinOrder = DiscoverJoinOrder(types, stSemanticTypes, typeIntersectionStructs);
  ...</pre>
<p>DiscoverJoinOrder looks simple...</p>
<pre>protected List&lt;TypeIntersection&gt; DiscoverJoinOrder(List&lt;string&gt; types, Dictionary&lt;string, List&lt;Tuple&lt;ISemanticTypeStruct, ISemanticTypeStruct&gt;&gt;&gt; stSemanticTypes, Dictionary&lt;TypeIntersection, List&lt;ISemanticTypeStruct&gt;&gt; typeIntersectionStructs)
{
  // For each root type, get all the sub-ST's.
  foreach (string st in types)
  {
    stSemanticTypes[st] = rsys.SemanticTypeSystem.GetAllSemanticTypes(st);
  }

  List&lt;TypeIntersection&gt; joinOrder = GetJoinOrder(types, stSemanticTypes, typeIntersectionStructs);

  return joinOrder;
}</pre>
<p>... but it's deceptive, because the real work is in <code>GetJoinOrder</code>.&nbsp; 
This function is not very efficient, but it gets the job done for now.&nbsp; The 
concept is:</p>
<ol>
	<li>Starting with the first structure (the root structure), try and join it 
	with some other following structure. </li>
	<li>Once we've found a shared structure, remove it from the list and start 
	over again, trying to resolve the next structure in the join list.</li>
</ol>
<p>This process ensures that we create joins so that they are declared before 
being referenced by other joins:</p>
<pre>/// &lt;summary&gt;
/// Iterate until all joins are resolved.
/// &lt;/summary&gt;
protected List&lt;TypeIntersection&gt; GetJoinOrder(List&lt;string&gt; types, Dictionary&lt;string, List&lt;Tuple&lt;ISemanticTypeStruct, ISemanticTypeStruct&gt;&gt;&gt; stSemanticTypes, Dictionary&lt;TypeIntersection, List&lt;ISemanticTypeStruct&gt;&gt; typeIntersectionStructs)
{
  // We assume that the first ST is always the &quot;base&quot; ST, and everything else is joined to it or to other ST's.
  // This requires that we process joins 1..n in a specific order to ensure that joins to ST's are first defined, then referenced.
  // TODO: We do not have a test for that.
  List&lt;TypeIntersection&gt; joinOrder = new List&lt;TypeIntersection&gt;();
  List&lt;string&gt; typesToJoin = new List&lt;string&gt;();

  // We need to join all these types.
  // These may become &quot;base&quot; types if we have a dependency like:
  // 1 depends on 2, and 2 depends on 0.
  // To resolve 1, we first discover that 2 depends on 0
  // We then iterate again with 2 as the base type and discover that we can now join 1 as a dependency on 2.
  // The resulting order is then 0, 2, 1.
  typesToJoin.AddRange(types.Skip(1));

  // Assume idx 0 is the base.
  int baseIdx = 0;

  // Do we have any types left to join?
  while (typesToJoin.Count &gt; 0)
  {
    int idx = 0;
    bool found = false;

    // Easier to debug if we don't use anonymous methods. Better for stack traces on exceptions too!
    foreach (string typeToJoin in types)
    {
      // Skip any type that we already found a join for (it won't be in the list.)
      if (!typesToJoin.Contains(typeToJoin))
      {
        ++idx;
        continue;
      }

      // Returns a list of intersecting ST's between the base ST and another ST.
      List&lt;ISemanticTypeStruct&gt; sharedStructs = stSemanticTypes[types[baseIdx]].Select(t1 =&gt; t1.Item1).Intersect(stSemanticTypes[types[idx]].Select(t2 =&gt; t2.Item1)).ToList();

      // If we have shared structure...
      if (sharedStructs.Count &gt; 0)
      {
        // TODO: We still need to verify that we have unique keys in which to accomplish a join.
        // Write a test for this.
        // (For now, we always assume that we do)
        TypeIntersection typeIntersection = new TypeIntersection(types[baseIdx], types[idx]);
        typeIntersectionStructs[typeIntersection] = sharedStructs;
        joinOrder.Add(typeIntersection);
        typesToJoin.Remove(types[idx]);
        found = true;
        // Try next type.
        break;
      }

      ++idx;
    }

    if (found)
    {
      // Start with the base again.
      baseIdx = 0;
    }
    else
    {
      // TODO: Determine what type failed to join so we can put out a more intelligent exception.
      throw new Exception(&quot;Cannot find a common type for the required join.&quot;);
    }
  }

  return joinOrder;
}</pre>
<p>We continue setting up various structures that will be used for constructing 
the full query and build the pieces for the first (root) semantic structure:</p>
<pre>// Since we always start with the first ST in the join list as the base type:
List&lt;ISemanticTypeStruct&gt; sharedStructs = typeIntersectionStructs[joinOrder[0]];
ISemanticTypeStruct sharedStruct = sharedStructs[0];
string baseType = joinOrder[0].BaseType;

ISemanticTypeStruct parent0 = stSemanticTypes[baseType].Single(t =&gt; t.Item1 == sharedStruct).Item2;
bool parent0ElementUnique = parent0.SemanticElements.Any(se =&gt; se.Name == sharedStruct.DeclTypeName &amp;&amp; se.UniqueField);

// Build the query pieces for the first type:
ISemanticTypeStruct sts0 = rsys.SemanticTypeSystem.GetSemanticTypeStruct(baseType);
List&lt;string&gt; fields0 = new List&lt;string&gt;();
List&lt;string&gt; joins0 = new List&lt;string&gt;();
List&lt;Tuple&lt;string, string&gt;&gt; fqntAliases = new List&lt;Tuple&lt;string, string&gt;&gt;();

BuildQuery(sts0, fields0, joins0, structureUseCounts, sts0.DeclTypeName, fqntAliases);</pre>
<p>We now have the set of fields and required joins to populate those fields for 
the first structure.</p>
<p>We then iterate through the remaining structures, in the order determined 
earlier:</p>
<pre>// Now we're ready to join the other ST's, which are always joinOrder[joinIdx].JoinType.
for (int joinIdx = 0; joinIdx &lt; joinOrder.Count; joinIdx++)
{
  string joinType = joinOrder[joinIdx].JoinType;
  FixupBaseType(stSemanticTypes, sharedStruct, joinOrder, joinIdx, ref baseType, ref parent0, ref parent0ElementUnique);</pre>
<p>It's necessary to always keep track of what structure we're joining to.&nbsp; 
If structure 0 is joined with structure 1, but structure 2 joins with structure 
1, then we to update our &quot;base&quot; type so that it is now structure 1.&nbsp; This 
is what <code>FixupBaseType</code> does:</p>
<pre>protected void FixupBaseType(Dictionary&lt;string, List&lt;Tuple&lt;ISemanticTypeStruct, ISemanticTypeStruct&gt;&gt;&gt; stSemanticTypes, ISemanticTypeStruct sharedStruct, List&lt;TypeIntersection&gt; joinOrder, int joinIdx, ref string baseType, ref ISemanticTypeStruct parent0, ref bool parent0ElementUnique)
{
  // If we've changed the &quot;base&quot; type, then update parent0 and parent0ElementUnique.
  if (joinOrder[joinIdx].BaseType != baseType)
  {
    baseType = joinOrder[joinIdx].BaseType;
    parent0 = stSemanticTypes[baseType].Single(t =&gt; t.Item1 == sharedStruct).Item2;
    parent0ElementUnique = parent0.SemanticElements.Any(se =&gt; se.Name == sharedStruct.DeclTypeName &amp;&amp; se.UniqueField);
  }
}</pre>
<p>It ensures that the table we are &quot;joining on&quot; is the right-hand side of the 
join declaration.</p>
<p>Next, we obtain the shared structure between the &quot;base&quot; structure and the 
structure to which we're joining to.&nbsp; There's more code comments here than 
code:</p>
<pre>sharedStructs = typeIntersectionStructs[joinOrder[joinIdx]];

// If the shared structure is a unique field in both parent structures, then we can do then join with the FK_ID's rather than the underlying data.
// So, for example, in the UniqueKeyJoinQuery unit test, we can join RSSFeedItem and Visited with:
// &quot;join [one of the tables] on RSSFeedItem.FK_UrlID = Visited.FK_UrlID&quot; (ignoring aliased table names)
// IMPORTANT: Where the parent tables in the &quot;on&quot; statement are the parents of the respective shared structure, not the root query structure name (which just so happens to be the same in this case.)

// If there is NOT a unique key at either or both ends, then we have to drill into all native types at the joined structure level for both query paths, which would look like:
// &quot;join [one of the tables] on Url1.Value = Url2.Value [and...]&quot; where the and aggregates all the NT values shared between the two query paths.
// Notice that here it is VITAL that we figure out the aliases for each query path.

// Interestingly, if both reference is unique structure, we get an intersection.
// If both reference a non-unique structure, we get an intersection, but then we need to check the parent to see if the element is unique for both paths.

// TODO: At the moment, we just pick the first shared structure. At some point we want to pick one that can work with FK's first, then NT unique key values if we can't find an FK join.
// TODO: If there's more than one shared structure, try an pick the one that is unique or who's parent is a unique element.
// TODO: Write a unit test for this.
sharedStruct = sharedStructs[0];</pre>
<p>A shared structure requires that we obtain the parent structures which have a 
semantic element that matches the shared structure:</p>
<pre>// Find the parent for each root query given the shared structure.
ISemanticTypeStruct parent1 = stSemanticTypes[joinType].Single(t =&gt; t.Item1 == sharedStruct).Item2;
bool parent1ElementUnique = parent1.SemanticElements.Any(se =&gt; se.Name == sharedStruct.DeclTypeName &amp;&amp; se.UniqueField);</pre>
<p><img border="0" src="note.png" width="24" height="32"> Because we're always 
drilling into the entire semantic structure for a particular structure, this 
piece of code does something very deceptive -- it allows us to find the parent
<i>anywhere </i>in the structure tree.&nbsp; This is very important, because we 
can join semantic structures &quot;at the hip&quot;, as it were -- in other words, 
anywhere where the shared structure is encountered between the two semantic 
trees.</p>
<p>At this point we also have two important flags:</p>
<ul>
	<li>parent0ElementUnique</li>
	<li>parent1ElementUnique</li>
</ul>
<p>This is important because it informs the process that we can use foreign keys 
for the joins rather than native type unique fields.&nbsp; We see this test 
performed next:</p>
<pre>// If the shared structure is unique, or the elements referencing the structure are unique in both parents, then we can use the FK ID between the two parent ST's to join the structures.
// Otherwise, we have to use the NT values in each structure.
if ((sharedStruct.Unique) || (parent0ElementUnique &amp;&amp; parent1ElementUnique))
{
...</pre>
<p>If we know that the shared structure is declared unique, or that we have 
unique elements for both parents, we can use the foreign key values to join the 
two tables.&nbsp; First, we build up the fields and joins for table we are 
joining:</p>
<pre>// Build the query pieces for the second type, preserving counts so we don't accidentally re-use an alias.
ISemanticTypeStruct sts1 = rsys.SemanticTypeSystem.GetSemanticTypeStruct(joinType);
List&lt;string&gt; fields1 = new List&lt;string&gt;();
List&lt;string&gt; joins1 = new List&lt;string&gt;();

BuildQuery(sts1, fields1, joins1, structureUseCounts, sts1.DeclTypeName, fqntAliases);
fields0.AddRange(fields1);</pre>
<p>Those fields are added to our &quot;master&quot; set of fields being queried.</p>
<p>Next, we construct the structure-structure join:</p>
<pre>// Note the root element of the second structure is always aliased as &quot;1&quot;.
// TODO: This doesn't handle self joins. Scenario? Unit test? Test and throw exception?
// IMPORTANT: In Postgres, we note that the join that declares the table referenced in joins1 must be joined first.
// TODO: We use a left join here because we want to include records from the first table that may not match with the second table. This should be user definable, perhaps the way Oracle used to do it with the &quot;+&quot; to indicate a left join rather than an inner join.
// TODO: The root table name of the second table (parent1) doesn't need an &quot;as&quot; because it will only be referenced once (like in the &quot;from&quot; clause for parent0), however, this means 
// that we can't join the same type twice. When will this be an issue?

// Except for types in the query itself, we need to aliased type.
string rightSideTableName = parent0.DeclTypeName;

if (!types.Contains(parent0.DeclTypeName))
{
  rightSideTableName = parent0.DeclTypeName + &quot;1&quot;; // TODO: But do we need to know which alias, out of a possibility of aliases, to choose from???
}

if (sharedStruct.DeclTypeName == parent0.DeclTypeName)
{
  // The right side should, in this case, be the ID, not an FK, as the left side is joining to the actual table rather than both referencing a common shared FK.
  joins0.Add(&quot;left join &quot; + parent1.DeclTypeName + &quot; on &quot; + parent1.DeclTypeName + &quot;.FK_&quot; + sharedStruct.DeclTypeName + &quot;ID = &quot; + rightSideTableName + &quot;.ID&quot;);
}
else
{
  joins0.Add(&quot;left join &quot; + parent1.DeclTypeName + &quot; on &quot; + parent1.DeclTypeName + &quot;.FK_&quot; + sharedStruct.DeclTypeName + &quot;ID = &quot; + rightSideTableName + &quot;.FK_&quot; + sharedStruct.DeclTypeName + &quot;ID&quot;);
}

joins0.AddRange(joins1);</pre>
<p>And finally, we add the joins specific for the second structure -- these are 
joins for drilling into the structure, not for joining two structures together:</p>
<pre>joins0.AddRange(joins1);</pre>
<p>And amusingly, because I've not had to do this yet, joining by unique native 
types is not implemented:</p>
<pre>else
{
  // TODO: Implement a join based on NT unique key values, as we're joining an ST with only NT's.
  throw new Exception(&quot;Non-FK joins are currently not supported.&quot;);
}</pre>
<p>Finally, after all the table joins have been created, we finish the SQL 
statement and begin reading the results:</p>
<pre>string sqlQuery = &quot;select &quot; + String.Join(&quot;, &quot;, fields0) + &quot; \r\nfrom &quot; + sts0.DeclTypeName + &quot; \r\n&quot; + String.Join(&quot; \r\n&quot;, joins0);
sqlQuery = sqlQuery + &quot; &quot; + ParseOrderBy(orderBy, fqntAliases);
sqlQuery = dbio.AddLimitClause(sqlQuery, maxRecords);

ReadResults(sqlQuery);</pre>
<p>We read the root structure and all the joined structures, building the 
resulting new semantic structure culminating (finally!) in emitting a carrier 
with the custom protocol and the signal:</p>
<pre>while (reader.Read())
{
  int counter = 0;
  List&lt;object&gt; joinSignals = new List&lt;object&gt;();

  // The resulting fields are in the order of how they're populated based on our join list.
  object outsignal0 = PopulateStructure(types[0], reader, ref counter);
  PopulateJoinStructures(joinSignals, joinOrder, reader, ref counter);

  // Now create a custom type if it doesn't already exist. The custom type name is formed from the type names in the join.
  ISemanticTypeStruct outprotocol;
  object outsignal = CreateCustomType(types, out outprotocol);

  // Assign our signals to the children of the custom type. 
  // TODO: Again, self-joins will fail here.
  SetValue(outsignal, types[0], outsignal0);
  SetJoinedSignals(outsignal, joinOrder, joinSignals);

  // Finally! Create the carrier:
  rsys.CreateCarrier(this, outprotocol, outsignal);
}</pre>
<p><img border="0" src="note.png" width="24" height="32">&nbsp; Note that this 
creates a carrier for each row.&nbsp; Implementing a collection of 
protocol-signals that can be placed onto a single carrier is on the todo list.</p>
<h3>Three Structure Join Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; This all 
becomes more interesting when testing, for example, a three structure join, set 
up like this:</p>
<pre>protected void InitFeedUrlWithUniqueElements()
{
  SemanticTypeStruct stsUrl = Helpers.CreateSemanticType(&quot;Url&quot;, false, decls, structs);
  Helpers.CreateNativeType(stsUrl, &quot;Value&quot;, &quot;string&quot;, true);

  SemanticTypeStruct stsVisited = Helpers.CreateSemanticType(&quot;Visited&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsVisited, &quot;Url&quot;, true);
  Helpers.CreateNativeType(stsVisited, &quot;Count&quot;, &quot;int&quot;, false);

  // For 3 ST join tests.
  SemanticTypeStruct stsDisplayed = Helpers.CreateSemanticType(&quot;Displayed&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsDisplayed, &quot;Url&quot;, true);

  SemanticTypeStruct stsFeedUrl = Helpers.CreateSemanticType(&quot;RSSFeedUrl&quot;, false, decls, structs);
  Helpers.CreateSemanticElement(stsFeedUrl, &quot;Url&quot;, true);
}</pre>
<p>This test sets up four structures: Url, Visited, Displayed, and RSSFeedUrl:</p>
<pre>protected void ThreeSemanticTypesJoinTest()
{
  DropTable(&quot;Url&quot;);
  DropTable(&quot;Visited&quot;);
  DropTable(&quot;Displayed&quot;);
  DropTable(&quot;RSSFeedUrl&quot;);
  DropTable(&quot;RSSFeedItemDisplayed&quot;);

  sdr.Protocols = &quot;RSSFeedUrl; Visited; Displayed&quot;;
  sdr.ProtocolsUpdated();
  sdr.UnitTesting = true;

  // The schema defines that:
  // URL is a unique structure
  // RSSFeedUrl.Url is unique (no duplicates pointing to the same Url)
  // Visited.Url is unique (no duplicates pointing to the same Url)

  ICarrier feedUrlCarrier1 = Helpers.CreateCarrier(rsys, &quot;RSSFeedUrl&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://localhost&quot;;
  });

  // A URL we will not be joining on because we don't have a Visited record.
  ICarrier feedUrlCarrier2 = Helpers.CreateCarrier(rsys, &quot;RSSFeedUrl&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://www.codeproject.com&quot;;
  });

  ICarrier visitedCarrier = Helpers.CreateCarrier(rsys, &quot;Visited&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://localhost&quot;;
    signal.Count = 1; // non-zero value to make sure that we're not getting a default value back.
  });

  ICarrier displayedCarrier = Helpers.CreateCarrier(rsys, &quot;Displayed&quot;, signal =&gt;
  {
    signal.Url.Value = &quot;http://www.codeproject.com&quot;;
  });

  sdr.ProcessCarrier(feedUrlCarrier1);
  sdr.ProcessCarrier(feedUrlCarrier2);
  sdr.ProcessCarrier(visitedCarrier);
  sdr.ProcessCarrier(displayedCarrier);

  // Create the query
  ICarrier queryCarrier = Helpers.CreateCarrier(rsys, &quot;Query&quot;, signal =&gt;
  {
    // *** The order here is important, because the second join will be a left join ***
    // TODO: This needs to be exposed to the user somehow.
    signal.QueryText = &quot;RSSFeedUrl, Visited, Displayed&quot;;
  });

  sdr.ProcessCarrier(queryCarrier);
  List&lt;QueuedCarrierAction&gt; queuedCarriers = rsys.QueuedCarriers;
  Assert.AreEqual(2, queuedCarriers.Count, &quot;Expected two signals to be returned.&quot;);

  // The result, using a left join, is:

  // &quot;http://localhost&quot;; 1; &quot;http://localhost&quot;
  // &quot;http://www.codeproject.com&quot;; ; &quot;&quot; &lt;-- notice the Visited portion is null, however the &quot;displayed&quot; portion is NOT null.

  // This is a new ST that isn't defined in our schema.
  dynamic retSignal = queuedCarriers[0].Carrier.Signal;
  Assert.AreEqual(&quot;http://localhost&quot;, retSignal.RSSFeedUrl.Url.Value, &quot;Unexpected URL value.&quot;);
  Assert.AreEqual(1, retSignal.Visited.Count);
  Assert.AreEqual(null, retSignal.Displayed);

  retSignal = queuedCarriers[1].Carrier.Signal;
  Assert.AreEqual(&quot;http://www.codeproject.com&quot;, retSignal.RSSFeedUrl.Url.Value, &quot;Unexpected URL value.&quot;);
  Assert.AreEqual(null, retSignal.Visited);
  Assert.AreNotEqual(null, retSignal.Displayed);
}  </pre>
<p>The resulting query looks like this:</p>
<pre>select Url1.Value, Visited.Count, Url2.Value, Url3.Value 
from RSSFeedUrl 
left join Url as Url1 on Url1.ID = RSSFeedUrl.FK_UrlID 
left join Visited on Visited.FK_UrlID = RSSFeedUrl.FK_UrlID 
left join Url as Url2 on Url2.ID = Visited.FK_UrlID 
left join Displayed on Displayed.FK_UrlID = RSSFeedUrl.FK_UrlID 
left join Url as Url3 on Url3.ID = Displayed.FK_UrlID </pre>
<p>with the data being returned looking like this:</p>
<p><img border="0" src="query4.png" width="650" height="119"></p>
<h2>To Be Continued...</h2>
<p>While there are several important todo's in the code, we have a sufficient 
implementation to actually do something useful.&nbsp; In a
<a href="http://www.codeproject.com/Articles/797457/The-Semantic-Web-and-Natural-Language-Processing">
previous article</a>, I explored RSS Feeds in relationship to natural language 
processing.&nbsp; In the next article, we'll use the semantic database to put 
together a feed reader application that includes persistence of &quot;visited&quot; and 
&quot;displayed&quot; states.&nbsp; We'll look at:</p>
<ul>
	<li>the semantic structures to support the application</li>
	<li>the receptors used</li>
	<li>how to add diagnostics while building HOPE applets</li>
	<li>viewing the SQL generated by the database engine</li>
</ul>
<p>As a teaser, here's a screenshot of the applet, processing five different 
&quot;tech&quot; feeds:</p>
<p>&nbsp;</p>
<h2>References</h2>
<p>1 - Semantic Data -
<a href="http://en.wikipedia.org/wiki/Semantic_data_model">
http://en.wikipedia.org/wiki/Semantic_data_modell</a><br>
2 - Semantic Web - <a href="http://en.wikipedia.org/wiki/Semantic_Web">
http://en.wikipedia.org/wiki/Semantic_Web</a> <br>
3 - Web Ontology Language -
<a href="http://en.wikipedia.org/wiki/Web_Ontology_Language">
http://en.wikipedia.org/wiki/Web_Ontology_Language</a><br>
4 - Resource Description Format -
<a href="http://en.wikipedia.org/wiki/Resource_Description_Framework">
http://en.wikipedia.org/wiki/Resource_Description_Framework</a><br>
5 - schema.org -
<a href="http://www.schema.org/">schema.org</a><br>
6 - Semantics - <a href="http://en.wikipedia.org/wiki/Semantics">
http://en.wikipedia.org/wiki/Semantics</a><br>
7 - Tim Berners-Lee - <a href="http://en.wikipedia.org/wiki/Tim_Berners-Lee">
http://en.wikipedia.org/wiki/Tim_Berners-Lee</a><br>
8 - Semantics - <a href="http://en.wikipedia.org/wiki/Semantics">
http://en.wikipedia.org/wiki/Semantics</a><br>
9 - Ontology - 
<a href="http://en.wikipedia.org/wiki/Ontology_(information_science)">Ontology 
(information science)</a><br>
10 - Friend of a Friend - <a href="http://www.foaf-project.org/">
Friend of a Friend</a><br>
11 - W3C SKOS Core Guild -
<a href="http://www.w3.org/TR/2005/WD-swbp-skos-core-guide-20051102/">W3C SKOS 
Core Guide</a><br>
12 - RDF Schema - <a href="http://en.wikipedia.org/wiki/RDF_Schema">
http://en.wikipedia.org/wiki/RDF_Schema</a><br>
13 - Neo4j -
<a href="http://neo4j.com/blog/and-now-for-something-completely-different-using-owl-with-neo4j/">
http://neo4j.com/</a><br>14 - Cypher -
<a href="http://docs.neo4j.org/chunked/snapshot/cypher-query-lang.html">Cypher</a> </p></p>

</body>

</html>